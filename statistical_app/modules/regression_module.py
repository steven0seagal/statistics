"""
Regression Analysis Module
==========================

A comprehensive module for performing and comparing linear and logarithmic regression analysis.
Includes demo data generation, model fitting, visualization, and interpretation.

Author: Assistant
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import plotly.express as px
import plotly.graph_objects as go


def get_demo_data_linear():
    """Generate demo data with linear relationship"""
    X = np.linspace(1, 50, 100)
    y = 2.5 * X + 4 + np.random.randn(100) * 8  # Strong linear correlation + noise
    return pd.DataFrame({'X_lin': X, 'Y_lin': y})


def get_demo_data_log():
    """Generate demo data with logarithmic relationship"""
    X = np.linspace(1, 50, 100)
    y = 3 * np.log(X) + 2 + np.random.randn(100) * 0.5  # Logarithmic correlation + noise
    return pd.DataFrame({'X_log': X, 'Y_log': y})


def run_regression_module():
    """Main function for the regression analysis module"""

    st.title(" Modu Analizy Regresji")
    st.markdown("Analizuj i por贸wnuj modele regresji liniowej i logarytmicznej.")

    # === SECTION 1: DATA SOURCE ===
    st.sidebar.header("1. Wprowad藕 Dane")
    data_source = st.sidebar.radio(
        "Wybierz 藕r贸do danych:",
        ("U偶yj danych demo", "Wprowad藕 wasne dane")
    )

    df = None  # Initialize DataFrame

    # --- Demo Data ---
    if data_source == "U偶yj danych demo":
        demo_type = st.sidebar.selectbox("Wybierz typ danych demo:", ["Dane Liniowe", "Dane Logarytmiczne"])
        if demo_type == "Dane Liniowe":
            df = get_demo_data_linear()
        else:
            df = get_demo_data_log()

    # --- Custom Data ---
    else:
        uploaded_file = st.sidebar.file_uploader("Wgraj plik CSV lub Excel", type=["csv", "xlsx"])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
            except Exception as e:
                st.error(f"Bd podczas wczytywania pliku: {e}")

    # If data not loaded, stop here
    if df is None or df.empty:
        st.info("Prosz wczyta dane lub wybra zestaw demo, aby rozpocz analiz.")
        st.stop()

    st.subheader("Podgld Danych")
    st.dataframe(df.head())

    # === SECTION 2: VARIABLE SELECTION ===
    st.sidebar.header("2. Konfiguracja Modelu")

    # Select only numeric columns
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

    if len(numeric_cols) < 2:
        st.warning("Twoje dane musz zawiera co najmniej dwie kolumny numeryczne.")
        st.stop()

    # KROK 1: Najpierw wybierz zmienn ZALE呕N (Y)
    col_y = st.sidebar.selectbox("Wybierz zmienn zale偶n (Y - prognozowan):", numeric_cols)

    # KROK 2: Reszta kolumn jest dostpna jako predyktory (X)
    available_x_cols = [col for col in numeric_cols if col != col_y]

    if not available_x_cols:
        st.warning(f"Brak dostpnych zmiennych (X) do prognozowania {col_y}.")
        st.stop()

    # KROK 3: U偶yj MULTISELECT dla zmiennych X
    cols_x = st.sidebar.multiselect(
        "Wybierz zmienne niezale偶ne (X - predyktory):",
        available_x_cols,
        default=available_x_cols[0] if available_x_cols else None,
        help="Wybierz JEDN zmienn dla regresji prostej/logarytmicznej lub WIELE zmiennych dla regresji wielokrotnej."
    )

    if not cols_x:
        st.info("Prosz wybra co najmniej jedn zmienn niezale偶n (X), aby rozpocz analiz.")
        st.stop()

    # === SECTION 3: ANALYSIS AND RESULTS ===

    # Prepare data (remove missing values)
    all_cols = [col_y] + cols_x
    analysis_df = df[all_cols].dropna()
    X_raw = analysis_df[cols_x]
    y = analysis_df[col_y]

    if X_raw.empty or y.empty:
        st.error("Wybrane kolumny nie zawieraj danych po usuniciu brak贸w (NaN).")
        st.stop()

    st.header("Wyniki Analizy Regresji")

    # --- ROZGAZIENIE LOGIKI ---

    # ===== PRZYPADEK 1: REGRESJA PROSTA I LOGARYTMICZNA (1 predyktor X) =====
    if len(cols_x) == 1:
        st.info("Wykryto 1 predyktor (X). Przeprowadzam analiz regresji prostej i logarytmicznej.")

        # Zmie nazw X_raw na X_simple, aby byo jasne
        col_x_name = cols_x[0]
        X_simple = X_raw[[col_x_name]]  # sklearn wymaga 2D DataFrame

        col1, col2 = st.columns(2)

        # --- Model Liniowy Prosty ---
        with col1:
            st.subheader("Model Liniowy Prosty")
            st.markdown("`y = a * x + b`")

            model_lin = LinearRegression()
            model_lin.fit(X_simple, y)
            y_pred_lin = model_lin.predict(X_simple)

            a_lin = model_lin.coef_[0]
            b_lin = model_lin.intercept_
            r2_lin = r2_score(y, y_pred_lin)
            mse_lin = mean_squared_error(y, y_pred_lin)

            st.metric("R-kwadrat (R虏)", f"{r2_lin:.4f}")
            st.metric("Bd redniokw. (MSE)", f"{mse_lin:.4f}")
            st.write(f"**Wz贸r:** `y = {a_lin:.3f} * x + {b_lin:.3f}`")
            st.caption(f"U偶ywasz: {col_x_name}")

        # --- Model Logarytmiczny ---
        with col2:
            st.subheader("Model Logarytmiczny")
            st.markdown("`y = a * ln(x) + b`")

            # Logarithmic model requires X > 0
            log_df = analysis_df[analysis_df[col_x_name] > 0]
            if log_df.empty:
                st.warning("Model logarytmiczny wymaga wartoci X > 0. Brak danych do analizy.")
                r2_log, mse_log, a_log, b_log = (np.nan,) * 4  # Set as NaN
            else:
                X_log_transformed = np.log(log_df[[col_x_name]])  # Transform X -> ln(X)
                y_log_target = log_df[col_y]

                model_log = LinearRegression()
                model_log.fit(X_log_transformed, y_log_target)
                y_pred_log = model_log.predict(X_log_transformed)

                a_log = model_log.coef_[0]
                b_log = model_log.intercept_
                r2_log = r2_score(y_log_target, y_pred_log)
                mse_log = mean_squared_error(y_log_target, y_pred_log)

                st.metric("R-kwadrat (R虏)", f"{r2_log:.4f}")
                st.metric("Bd redniokw. (MSE)", f"{mse_log:.4f}")
                st.write(f"**Wz贸r:** `y = {a_log:.3f} * ln(x) + {b_log:.3f}`")
                st.caption(f"U偶ywasz: ln({col_x_name}). Analiza na {len(log_df)} wierszach (gdzie {col_x_name} > 0).")

        # --- Wizualizacja 2D ---
        st.subheader("Wizualizacja Dopasowania")

        # Create scatter plot
        fig = px.scatter(
            analysis_df,
            x=col_x_name,
            y=col_y,
            title="Dopasowanie Modeli Regresji",
            labels={col_x_name: f"X: {col_x_name}", col_y: f"Y: {col_y}"}
        )

        # Add linear regression line
        fig.add_trace(
            go.Scatter(
                x=X_simple[col_x_name],
                y=y_pred_lin,
                mode='lines',
                name=f"Liniowa (R虏={r2_lin:.3f})",
                line=dict(color='red', width=3)
            )
        )

        # Add logarithmic regression line (if calculated)
        if not np.isnan(r2_log):
            # Sort values for smooth line
            log_df_sorted = log_df.sort_values(by=col_x_name)
            X_log_plot = np.log(log_df_sorted[[col_x_name]])
            y_pred_log_plot = model_log.predict(X_log_plot)

            fig.add_trace(
                go.Scatter(
                    x=log_df_sorted[col_x_name],
                    y=y_pred_log_plot,
                    mode='lines',
                    name=f"Logarytm. (R虏={r2_log:.3f})",
                    line=dict(color='green', width=3)
                )
            )

        st.plotly_chart(fig, use_container_width=True)


    # ===== PRZYPADEK 2: WIELOKROTNA REGRESJA LINIOWA (>1 predyktor X) =====
    elif len(cols_x) > 1:
        st.info(f"Wykryto {len(cols_x)} predyktory (X). Przeprowadzam wielokrotn regresj liniow (MLR).")

        st.subheader("Wielokrotna Regresja Liniowa (MLR)")

        # Model jest ten sam, ale karmimy go wieloma kolumnami X
        model_mlr = LinearRegression()
        model_mlr.fit(X_raw, y)
        y_pred_mlr = model_mlr.predict(X_raw)

        r2_mlr = r2_score(y, y_pred_mlr)
        mse_mlr = mean_squared_error(y, y_pred_mlr)

        # Obliczanie R-kwadrat Skorygowanego (Adjusted R虏)
        n = len(y)  # liczba obserwacji
        p = len(cols_x)  # liczba predyktor贸w
        r2_adj = 0.0
        if n - p - 1 > 0:
            r2_adj = 1 - (1 - r2_mlr) * (n - 1) / (n - p - 1)

        # Wywietlanie metryk
        col1, col2, col3 = st.columns(3)
        col1.metric("R-kwadrat (R虏)", f"{r2_mlr:.4f}")
        col2.metric("R-kwadrat Skorygowany (Adjusted R虏)", f"{r2_adj:.4f}",
                   help="Wa偶niejszy ni偶 R虏 przy wielu zmiennych. Karze za dodawanie nieistotnych predyktor贸w.")
        col3.metric("Bd redniokw. (MSE)", f"{mse_mlr:.4f}")

        # Wywietlanie wzoru i wsp贸czynnik贸w
        st.markdown("**Wz贸r Modelu:**")
        intercept_b = model_mlr.intercept_
        coefficients_a = model_mlr.coef_

        formula = f"`{col_y} = {intercept_b:.3f}`"
        for i, (col, coef) in enumerate(zip(cols_x, coefficients_a)):
            sign = "+" if coef >= 0 else "-"
            formula += f" `{sign} ({abs(coef):.3f} * {col})`"
        st.code(formula, language='text')

        # Tabela wsp贸czynnik贸w
        st.markdown("**Wsp贸czynniki:**")
        coef_df = pd.DataFrame(
            {'Cecha (X)': ['Wyraz Wolny (Intercept)'] + cols_x,
             'Wsp贸czynnik (Waga)': [intercept_b] + list(coefficients_a)}
        )
        st.dataframe(coef_df.set_index('Cecha (X)').style.format("{:.4f}"))
        st.caption("Wsp贸czynnik pokazuje, o ile rednio zmieni si Y, gdy dana Cecha (X) wzronie o 1 jednostk, **przy zao偶eniu, 偶e pozostae cechy X si nie zmieniaj**.")

        # === Wizualizacja dla MLR ===
        st.subheader("Wizualizacja Wynik贸w MLR")
        st.markdown("Poniewa偶 mamy wiele wymiar贸w (X), nie mo偶emy narysowa prostej linii. Poni偶szy wykres pokazuje, jak **wartoci prognozowane** przez model maj si do **wartoci rzeczywistych**.")

        plot_df = pd.DataFrame({'Rzeczywiste (Y)': y, 'Prognozowane (Y_pred)': y_pred_mlr})
        fig_mlr = px.scatter(plot_df, x='Rzeczywiste (Y)', y='Prognozowane (Y_pred)',
                             title='Rzeczywiste vs. Prognozowane',
                             labels={'Rzeczywiste (Y)': f'Rzeczywiste {col_y}', 'Prognozowane (Y_pred)': 'Prognozowane przez Model'},
                             hover_data=plot_df.columns)

        # Dodaj lini idealnego dopasowania (y=x)
        fig_mlr.add_shape(type='line', x0=y.min(), y0=y.min(), x1=y.max(), y1=y.max(), line=dict(color='red', dash='dash', width=2), name="Idealne dopasowanie")
        st.plotly_chart(fig_mlr, use_container_width=True)

    # === SECTION 4: INTERPRETATION AND OVERFITTING ===
    st.header("Wyb贸r Modelu i Interpretacja")

    # ===== PRZYPADEK 1: REGRESJA PROSTA I LOGARYTMICZNA =====
    if len(cols_x) == 1:
        # Comparison
        if np.isnan(r2_log) and not np.isnan(r2_lin):
            st.info("Tylko model liniowy m贸g zosta obliczony (model logarytmiczny wymaga X > 0).")
        elif np.isnan(r2_lin) and np.isnan(r2_log):
            st.error("Nie mo偶na byo obliczy 偶adnego modelu.")
        else:
            # Compare R虏
            if r2_lin > r2_log:
                st.success(
                    f"**Model Liniowy wydaje si lepiej dopasowany.** Posiada wy偶szy wsp贸czynnik R虏 "
                    f"({r2_lin:.4f}) w por贸wnaniu do modelu logarytmicznego ({r2_log:.4f})."
                )
            elif r2_log > r2_lin:
                st.success(
                    f"**Model Logarytmiczny wydaje si lepiej dopasowany.** Posiada wy偶szy wsp贸czynnik R虏 "
                    f"({r2_log:.4f}) w por贸wnaniu do modelu liniowego ({r2_lin:.4f})."
                )
            else:
                st.info(f"Oba modele maj identyczny wsp贸czynnik R虏 ({r2_lin:.4f}).")

            # Compare MSE
            if mse_lin < mse_log:
                st.success(
                    f"Model Liniowy ma r贸wnie偶 **mniejszy bd redniokwadratowy (MSE)** "
                    f"({mse_lin:.4f} vs {mse_log:.4f}), co oznacza, 偶e jego prognozy s rednio bli偶sze "
                    f"rzeczywistym wartociom."
                )
            elif mse_log < mse_lin:
                st.success(
                    f"Model Logarytmiczny ma r贸wnie偶 **mniejszy bd redniokwadratowy (MSE)** "
                    f"({mse_log:.4f} vs {mse_lin:.4f}), co oznacza, 偶e jego prognozy s rednio bli偶sze "
                    f"rzeczywistym wartociom."
                )

        st.subheader("Uwaga na Overfitting (Przeuczenie)")
        st.warning(
            """
            **Czym jest Overfitting?**
            Przeuczenie (overfitting) ma miejsce, gdy model jest zbyt skomplikowany i "uczy si na pami"
            danych treningowych, w tym szumu, zamiast wychwytywa og贸lny trend.

            **Jak to si ma do nas?**
            Modele regresji prostej (liniowy i logarytmiczny) s modelami **bardzo prostymi**.
            Ryzyko przeuczenia jest tu **minimalne**.
            """
        )

    # ===== PRZYPADEK 2: WIELOKROTNA REGRESJA LINIOWA =====
    elif len(cols_x) > 1:
        st.info(f"**Interpretacja R-kwadrat Skorygowanego (Adjusted R虏):** U偶ywaj tej metryki do oceny modelu. Wynik {r2_adj:.4f} oznacza, 偶e model wyjania ok. {r2_adj*100:.1f}% zmiennoci w {col_y}, biorc pod uwag liczb u偶ytych predyktor贸w.")

        st.subheader("Uwaga na Overfitting (Przeuczenie)")
        st.warning(
            """
            **Ryzyko w MLR:** W Wielokrotnej Regresji Liniowej ryzyko przeuczenia **ronie wraz z liczb dodanych zmiennych (X)**.

            **Jak si chroni?**
            1.  **Patrz na R-kwadrat Skorygowany:** Zwyke R虏 **zawsze** ronie, gdy dodajesz nowe zmienne, nawet jeli s bez sensu. R-kwadrat Skorygowany "karze" model za dodawanie nieistotnych zmiennych. Jeli dodasz zmienn, a R虏 Skorygowany spadnie, prawdopodobnie ta zmienna jest zbdna.
            2.  **Multikolinearno (Wsp贸liniowo):** Uwa偶aj, jeli twoje zmienne X s ze sob silnie skorelowane (np. `wzrost_w_cm` i `wzrost_w_calach`). Mo偶e to prowadzi do niestabilnych wynik贸w i bdnych wsp贸czynnik贸w.
            3.  **Zasada Oszczdnoci:** Wybieraj najprostszy model (najmniej zmiennych X), kt贸ry daje *wystarczajco dobre* wyniki.
            """
        )

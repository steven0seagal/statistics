"""
Report Generator Module
======================

Creates comprehensive statistical analysis reports in various formats.
"""

import pandas as pd
import numpy as np
from datetime import datetime
import base64
from io import BytesIO
import json
import warnings

class ReportGenerator:
    """
    Generates comprehensive statistical analysis reports.
    """

    def __init__(self):
        self.report_templates = {
            'basic': self._create_basic_report,
            'comprehensive': self._create_comprehensive_report,
            'publication': self._create_publication_report
        }

    def generate_report(self, analysis_results, report_type='comprehensive', **kwargs):
        """
        Generate a statistical analysis report.

        Parameters:
        -----------
        analysis_results : dict
            Results from statistical analysis
        report_type : str
            Type of report ('basic', 'comprehensive', 'publication')
        **kwargs : additional parameters

        Returns:
        --------
        dict : Report content and metadata
        """
        try:
            generator = self.report_templates.get(report_type, self._create_comprehensive_report)
            return generator(analysis_results, **kwargs)
        except Exception as e:
            return {
                'error': f'Report generation failed: {str(e)}',
                'content': None
            }

    def _create_basic_report(self, results, **kwargs):
        """Create a basic statistical report."""

        report_content = f"""
# Statistical Analysis Report

## Analysis Overview
- **Test Performed:** {results.get('test_name', 'Unknown')}
- **Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Sample Size:** {results.get('sample_size', 'N/A')}

## Results Summary
- **Test Statistic:** {results.get('statistic', 'N/A')}
- **P-value:** {results.get('p_value', 'N/A')}
- **Effect Size:** {results.get('effect_size', 'N/A')}

## Interpretation
{kwargs.get('interpretation', 'No interpretation provided.')}

---
*Report generated by Statistical Testing Application*
"""

        return {
            'content': report_content,
            'format': 'markdown',
            'metadata': {
                'report_type': 'basic',
                'generation_time': datetime.now().isoformat(),
                'test_name': results.get('test_name')
            }
        }

    def _create_comprehensive_report(self, results, assumptions=None, interpretation=None, **kwargs):
        """Create a comprehensive statistical report."""

        test_name = results.get('test_name', 'Unknown Test')

        # Header section
        report_content = f"""
# Comprehensive Statistical Analysis Report

## Executive Summary
- **Analysis Type:** {test_name}
- **Date of Analysis:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Analyst:** Statistical Testing Application
- **Sample Size:** {results.get('sample_size', 'N/A')}

## Research Question and Methodology

### Test Selection
The {test_name} was selected based on the following criteria:
- Data type and distribution characteristics
- Study design (independent vs. paired samples)
- Number of groups or variables being compared
- Sample size considerations

### Data Summary
"""

        # Add data summary if available
        if 'group_means' in results:
            report_content += "#### Group Statistics\n"
            group_means = results['group_means']
            for i, group in enumerate(results.get('groups', [])):
                mean = group_means[i] if isinstance(group_means, list) else 'N/A'
                std = results.get('group_stds', [None])[i] if 'group_stds' in results else 'N/A'
                n = results.get('group_ns', [None])[i] if 'group_ns' in results else 'N/A'
                report_content += f"- **{group}:** Mean = {mean}, SD = {std}, n = {n}\n"

        # Assumptions section
        report_content += "\n## Assumption Checking\n"
        if assumptions:
            for assumption_name, assumption_result in assumptions.items():
                status = "✓ PASSED" if assumption_result.get('passed', False) else "⚠ VIOLATED"
                report_content += f"### {assumption_result.get('assumption', assumption_name)}\n"
                report_content += f"**Status:** {status}\n"
                report_content += f"**Details:** {assumption_result.get('message', 'No details available')}\n"

                if assumption_result.get('recommendations'):
                    report_content += "**Recommendations:**\n"
                    for rec in assumption_result['recommendations']:
                        report_content += f"- {rec}\n"
                report_content += "\n"
        else:
            report_content += "Assumption checking results not available.\n"

        # Results section
        report_content += "\n## Statistical Results\n"

        # Main test statistics
        report_content += "### Primary Test Statistics\n"
        if 'statistic' in results:
            report_content += f"- **Test Statistic:** {results['statistic']:.4f}\n"
        if 'p_value' in results:
            report_content += f"- **P-value:** {results['p_value']:.6f}\n"
        if 'degrees_freedom' in results:
            report_content += f"- **Degrees of Freedom:** {results['degrees_freedom']}\n"

        # Effect size
        if 'effect_size' in results:
            report_content += f"\n### Effect Size\n"
            report_content += f"- **Effect Size:** {results['effect_size']:.4f}\n"
            if 'effect_size_interpretation' in results:
                report_content += f"- **Interpretation:** {results['effect_size_interpretation']}\n"

        # Confidence intervals if available
        if 'confidence_intervals' in results:
            report_content += f"\n### Confidence Intervals\n"
            for var, ci in results['confidence_intervals'].items():
                report_content += f"- **{var}:** [{ci[0]:.4f}, {ci[1]:.4f}]\n"

        # Statistical interpretation
        report_content += "\n## Statistical Interpretation\n"
        if interpretation:
            report_content += interpretation
        else:
            report_content += "No interpretation provided.\n"

        # Additional test-specific results
        if test_name == 'ANOVA' and 'post_hoc_needed' in kwargs:
            report_content += "\n## Post-Hoc Analysis Recommendations\n"
            report_content += "Since the ANOVA result is significant, post-hoc tests are recommended to identify which specific groups differ.\n"
            report_content += "Suggested post-hoc tests:\n"
            report_content += "- Tukey's HSD for all pairwise comparisons\n"
            report_content += "- Bonferroni correction for multiple comparisons\n"

        # Power analysis if available
        if 'power_analysis' in kwargs:
            power_results = kwargs['power_analysis']
            report_content += "\n## Power Analysis\n"
            if 'observed_power' in power_results:
                report_content += f"- **Observed Power:** {power_results['observed_power']:.3f}\n"
            if 'sample_size_recommendations' in power_results:
                report_content += "- **Sample Size Recommendations:**\n"
                for effect_size, n_required in power_results['sample_size_recommendations'].items():
                    report_content += f"  - {effect_size} effect: {n_required} per group\n"

        # Limitations and considerations
        report_content += "\n## Limitations and Considerations\n"
        report_content += "### Statistical Limitations\n"
        report_content += "- Results are based on the assumption that the data meet the test requirements\n"
        report_content += "- Statistical significance does not necessarily imply practical significance\n"
        report_content += "- Correlation does not imply causation\n"

        if results.get('sample_size', 0) < 30:
            report_content += "- Small sample size may limit the generalizability of results\n"

        report_content += "\n### Recommendations for Future Research\n"
        report_content += "- Consider replication with independent samples\n"
        report_content += "- Evaluate practical significance alongside statistical significance\n"
        report_content += "- Consider effect size when interpreting results\n"

        # Methods section
        report_content += "\n## Methods and Technical Details\n"
        report_content += f"### Statistical Test: {test_name}\n"

        # Add test-specific technical details
        if test_name in ['Independent t-test', 'Welch\'s t-test']:
            report_content += "The t-test compares the means of two independent groups to determine if they are statistically different.\n"
        elif test_name == 'One-way ANOVA':
            report_content += "One-way ANOVA tests whether there are statistically significant differences between the means of three or more independent groups.\n"
        elif 'correlation' in test_name.lower():
            report_content += "Correlation analysis measures the strength and direction of the linear relationship between two continuous variables.\n"

        report_content += "\n### Software and Packages\n"
        report_content += "- Analysis performed using Python scientific computing libraries\n"
        report_content += "- Statistical tests implemented using SciPy and statsmodels\n"
        report_content += "- Visualizations created using Plotly\n"

        # Footer
        report_content += "\n---\n"
        report_content += "*Report generated by Statistical Testing Application*\n"
        report_content += f"*Generation time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"

        return {
            'content': report_content,
            'format': 'markdown',
            'metadata': {
                'report_type': 'comprehensive',
                'generation_time': datetime.now().isoformat(),
                'test_name': test_name,
                'has_assumptions': assumptions is not None,
                'has_interpretation': interpretation is not None
            }
        }

    def _create_publication_report(self, results, **kwargs):
        """Create a publication-ready statistical report."""

        test_name = results.get('test_name', 'Unknown Test')

        # More formal, concise reporting style
        report_content = f"""
# Statistical Analysis Results

## Methods
Statistical analysis was performed using {test_name}. """

        # Add method-specific details
        if 'sample_size' in results:
            report_content += f"The analysis included {results['sample_size']} observations. "

        # Results in publication format
        report_content += f"""

## Results
"""

        # Format results according to publication standards
        if 'statistic' in results and 'p_value' in results:
            stat_name = self._get_statistic_symbol(test_name)
            if 'degrees_freedom' in results:
                report_content += f"{stat_name}({results['degrees_freedom']}) = {results['statistic']:.3f}, p = {results['p_value']:.3f}"
            else:
                report_content += f"{stat_name} = {results['statistic']:.3f}, p = {results['p_value']:.3f}"

            # Add effect size if available
            if 'effect_size' in results:
                effect_symbol = self._get_effect_size_symbol(test_name)
                report_content += f", {effect_symbol} = {results['effect_size']:.3f}"

        # Add group statistics for comparison tests
        if 'group_means' in results and 'groups' in results:
            report_content += f"\n\nDescriptive statistics: "
            for i, group in enumerate(results['groups']):
                mean = results['group_means'][i] if isinstance(results['group_means'], list) else 'N/A'
                std = results.get('group_stds', [None])[i] if 'group_stds' in results else 'N/A'
                if i > 0:
                    report_content += ", "
                report_content += f"{group}: M = {mean:.2f}, SD = {std:.2f}"

        # Conclusion
        report_content += f"\n\n"
        if results.get('p_value', 1) <= 0.05:
            report_content += f"The analysis revealed a statistically significant result."
        else:
            report_content += f"No statistically significant effect was observed."

        # Add effect size interpretation
        if 'effect_size_interpretation' in results:
            report_content += f" The effect size was {results['effect_size_interpretation']}."

        return {
            'content': report_content,
            'format': 'markdown',
            'metadata': {
                'report_type': 'publication',
                'generation_time': datetime.now().isoformat(),
                'test_name': test_name,
                'style': 'APA'
            }
        }

    def _get_statistic_symbol(self, test_name):
        """Get the appropriate symbol for the test statistic."""
        symbols = {
            'Independent t-test': 't',
            'Welch\'s t-test': 't',
            'Paired t-test': 't',
            'One-way ANOVA': 'F',
            'Two-way ANOVA': 'F',
            'Mann-Whitney U test': 'U',
            'Wilcoxon signed-rank test': 'W',
            'Chi-squared test': 'χ²',
            'Kruskal-Wallis test': 'H',
            'Friedman test': 'χ²'
        }
        return symbols.get(test_name, 'Test statistic')

    def _get_effect_size_symbol(self, test_name):
        """Get the appropriate symbol for the effect size."""
        symbols = {
            'Independent t-test': "Cohen's d",
            'Welch\'s t-test': "Cohen's d",
            'Paired t-test': "Cohen's d",
            'One-way ANOVA': 'η²',
            'Two-way ANOVA': 'η²',
            'Mann-Whitney U test': 'r',
            'Wilcoxon signed-rank test': 'r',
            'Chi-squared test': "Cramér's V",
            'Pearson correlation': 'r',
            'Spearman correlation': 'ρ'
        }
        return symbols.get(test_name, 'Effect size')

    def export_to_html(self, report_content):
        """Convert markdown report to HTML."""
        try:
            import markdown
            html_content = markdown.markdown(report_content)

            # Add basic styling
            styled_html = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Statistical Analysis Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; }}
        h2 {{ color: #34495e; border-bottom: 1px solid #bdc3c7; }}
        h3 {{ color: #7f8c8d; }}
        .status-passed {{ color: #27ae60; }}
        .status-violated {{ color: #e74c3c; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
{html_content}
</body>
</html>
"""
            return styled_html
        except ImportError:
            return f"<pre>{report_content}</pre>"

    def export_to_pdf(self, report_content):
        """Convert report to PDF (placeholder - requires additional dependencies)."""
        # This would require libraries like reportlab or weasyprint
        # For now, return a message about PDF export
        return {
            'error': 'PDF export requires additional dependencies (reportlab or weasyprint)',
            'alternative': 'Use HTML export and print to PDF from browser'
        }

    def create_summary_table(self, results):
        """Create a summary table of results."""
        summary_data = []

        if 'test_name' in results:
            summary_data.append(['Test Type', results['test_name']])

        if 'sample_size' in results:
            summary_data.append(['Sample Size', str(results['sample_size'])])

        if 'statistic' in results:
            stat_name = self._get_statistic_symbol(results.get('test_name', ''))
            summary_data.append([f'{stat_name} Statistic', f"{results['statistic']:.4f}"])

        if 'p_value' in results:
            summary_data.append(['P-value', f"{results['p_value']:.6f}"])

        if 'effect_size' in results:
            effect_name = self._get_effect_size_symbol(results.get('test_name', ''))
            summary_data.append([f'{effect_name}', f"{results['effect_size']:.4f}"])

        if 'degrees_freedom' in results:
            summary_data.append(['Degrees of Freedom', str(results['degrees_freedom'])])

        return pd.DataFrame(summary_data, columns=['Statistic', 'Value'])

    def generate_methods_text(self, test_name, assumptions_met=True):
        """Generate methods section text for publications."""

        methods_templates = {
            'Independent t-test': "An independent samples t-test was conducted to compare means between two groups.",
            'Paired t-test': "A paired samples t-test was conducted to compare means between two related conditions.",
            'One-way ANOVA': "A one-way analysis of variance (ANOVA) was conducted to compare means across multiple groups.",
            'Mann-Whitney U test': "A Mann-Whitney U test was conducted as a non-parametric alternative to compare distributions between two groups.",
            'Wilcoxon signed-rank test': "A Wilcoxon signed-rank test was conducted as a non-parametric alternative for paired comparisons.",
            'Pearson correlation': "Pearson product-moment correlation was used to assess the linear relationship between variables.",
            'Spearman correlation': "Spearman rank correlation was used to assess the monotonic relationship between variables."
        }

        base_text = methods_templates.get(test_name, f"Statistical analysis was conducted using {test_name}.")

        if not assumptions_met:
            base_text += " A non-parametric alternative was selected due to violations of parametric assumptions."

        base_text += " Statistical significance was set at α = 0.05."

        return base_text

    def create_downloadable_report(self, report_content, format_type='markdown'):
        """Create a downloadable report file."""

        if format_type == 'html':
            content = self.export_to_html(report_content)
            mime_type = 'text/html'
            extension = 'html'
        elif format_type == 'txt':
            # Strip markdown formatting for plain text
            content = report_content.replace('#', '').replace('**', '').replace('*', '')
            mime_type = 'text/plain'
            extension = 'txt'
        else:  # markdown
            content = report_content
            mime_type = 'text/markdown'
            extension = 'md'

        # Create download data
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"statistical_analysis_report_{timestamp}.{extension}"

        # Encode content for download
        b64_content = base64.b64encode(content.encode()).decode()

        return {
            'content': content,
            'filename': filename,
            'mime_type': mime_type,
            'download_link': f"data:{mime_type};base64,{b64_content}"
        }
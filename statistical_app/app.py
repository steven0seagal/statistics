"""
Statistical Testing Streamlit Application
=========================================

A comprehensive tool for statistical analysis that provides:
- Intelligent test selection based on data characteristics
- Educational content about statistical tests
- Data upload and preprocessing
- Assumption checking and validation
- Results interpretation and visualization

Author: Assistant
"""

import streamlit as st
import pandas as pd
import numpy as np
from modules.test_selector import TestSelector
from modules.data_processor import DataProcessor
from modules.statistical_tests import StatisticalTests
from modules.assumption_checker import AssumptionChecker
from modules.visualizer import Visualizer
from modules.interpreter import ResultsInterpreter
from modules.advanced_tests import AdvancedStatisticalTests
from modules.power_analysis import PowerAnalysis
from modules.report_generator import ReportGenerator
from modules.post_hoc_tests import PostHocTests
from modules.regression_module import run_regression_module
from modules.clustering_module import run_clustering_module
import statistical_recommender

# Configure Streamlit page
st.set_page_config(
    page_title="Statistical Testing Tool",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #2c3e50;
        border-bottom: 2px solid #3498db;
        padding-bottom: 0.5rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """Main application function"""

    # Main header
    st.markdown('<h1 class="main-header">üìä Statistical Testing Tool</h1>', unsafe_allow_html=True)

    # Sidebar navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.selectbox(
        "Choose a page:",
        ["Home", "Test Selection Wizard", "Data Upload & Analysis",
         "Automatic Test Recommender", "Advanced Analysis",
         "Power Analysis", "Regression Analysis", "K-Means Clustering", "Educational Content", "Test Library"]
    )

    # Initialize session state
    if 'data' not in st.session_state:
        st.session_state.data = None
    if 'test_results' not in st.session_state:
        st.session_state.test_results = None
    if 'selected_test' not in st.session_state:
        st.session_state.selected_test = None

    # Route to different pages
    if page == "Home":
        show_home_page()
    elif page == "Test Selection Wizard":
        show_test_selection_wizard()
    elif page == "Data Upload & Analysis":
        show_data_analysis_page()
    elif page == "Automatic Test Recommender":
        statistical_recommender.run_recommender_tool()
    elif page == "Advanced Analysis":
        show_advanced_analysis_page()
    elif page == "Power Analysis":
        show_power_analysis_page()
    elif page == "Regression Analysis":
        run_regression_module()
    elif page == "K-Means Clustering":
        run_clustering_module()
    elif page == "Educational Content":
        show_educational_content()
    elif page == "Test Library":
        show_test_library()

def show_home_page():
    """Display the home page with application overview"""

    st.markdown("""
    <div class="info-box">
    <h3>Welcome to the Statistical Testing Tool</h3>
    <p>This comprehensive application helps you select, perform, and interpret statistical tests for biological research.</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        ### ü§ñ Automatic Test Recommender (NEW!)
        Upload your data and get:
        - Automatic column profiling
        - Assumption testing (normality, homoscedasticity)
        - Intelligent test recommendations
        - One-click test execution
        - Detailed interpretation
        """)

        st.markdown("""
        ### üß≠ Test Selection Wizard
        Get personalized test recommendations based on:
        - Your research question
        - Data characteristics
        - Study design
        - Sample size considerations
        """)

    with col2:
        st.markdown("""
        ### üìà Data Analysis
        Upload your data and:
        - Perform automatic assumption checking
        - Run statistical tests
        - Generate visualizations
        - Get interpretation guidance
        """)

        st.markdown("""
        ### üìö Educational Content
        Learn about:
        - Statistical test principles
        - When to use each test
        - Common pitfalls
        - Best practices
        """)

    st.markdown("""
    ---
    ### Quick Start Guide

    1. **New to statistics?** Start with the **Educational Content** to learn the basics
    2. **Want automatic recommendations?** Try the **Automatic Test Recommender** - just upload your data!
    3. **Have data ready?** Use the **Test Selection Wizard** to find the right test
    4. **Know your test?** Go directly to **Data Upload & Analysis**
    5. **Need reference?** Check the **Test Library** for detailed information
    """)

    # Sample datasets showcase
    st.markdown('<h3 class="section-header">üìä Sample Datasets</h3>', unsafe_allow_html=True)

    sample_datasets = {
        "Biological Growth Study": "Compare growth rates between treatment groups",
        "Gene Expression Analysis": "Analyze differential expression across conditions",
        "Clinical Trial Data": "Compare treatment effectiveness",
        "Ecological Survey": "Species abundance across habitats"
    }

    for dataset, description in sample_datasets.items():
        st.markdown(f"**{dataset}**: {description}")

def show_test_selection_wizard():
    """Display the test selection wizard"""

    st.markdown('<h2 class="section-header">üß≠ Test Selection Wizard</h2>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <p>Answer a few questions about your research to get personalized test recommendations.</p>
    </div>
    """, unsafe_allow_html=True)

    # Research question
    st.subheader("1. What is your research goal?")
    research_goal = st.radio(
        "Select your primary objective:",
        [
            "Compare means/medians between groups",
            "Assess relationship between two variables",
            "Predict an outcome from predictors",
            "Analyze frequencies/proportions"
        ]
    )

    # Variable characteristics
    st.subheader("2. Describe your variables")

    if research_goal == "Compare means/medians between groups":
        show_group_comparison_wizard()
    elif research_goal == "Assess relationship between two variables":
        show_relationship_wizard()
    elif research_goal == "Predict an outcome from predictors":
        show_prediction_wizard()
    elif research_goal == "Analyze frequencies/proportions":
        show_categorical_wizard()

def show_group_comparison_wizard():
    """Wizard for group comparison tests"""

    col1, col2 = st.columns(2)

    with col1:
        dependent_var_type = st.selectbox(
            "Dependent variable type:",
            ["Continuous (numerical)", "Ordinal (ranked)", "Binary (yes/no)"]
        )

        num_groups = st.selectbox(
            "Number of groups to compare:",
            ["Two groups", "Three or more groups"]
        )

    with col2:
        study_design = st.selectbox(
            "Study design:",
            ["Independent groups", "Paired/repeated measures"]
        )

        sample_size = st.number_input(
            "Sample size per group:",
            min_value=1, value=30
        )

    # Generate recommendation
    if st.button("Get Test Recommendation"):
        test_selector = TestSelector()
        recommendation = test_selector.recommend_test(
            goal="compare_groups",
            dependent_type=dependent_var_type,
            num_groups=num_groups,
            design=study_design,
            sample_size=sample_size
        )

        st.markdown(f"""
        <div class="success-box">
        <h4>Recommended Test: {recommendation['test_name']}</h4>
        <p><strong>Rationale:</strong> {recommendation['rationale']}</p>
        <p><strong>Alternative:</strong> {recommendation['alternative']}</p>
        </div>
        """, unsafe_allow_html=True)

        st.session_state.selected_test = recommendation['test_name']

def show_relationship_wizard():
    """Wizard for relationship analysis"""
    st.write("Relationship analysis wizard - Coming soon!")

def show_prediction_wizard():
    """Wizard for prediction analysis"""
    st.write("Prediction analysis wizard - Coming soon!")

def show_categorical_wizard():
    """Wizard for categorical analysis"""
    st.write("Categorical analysis wizard - Coming soon!")

def show_data_analysis_page():
    """Display the data analysis page"""

    st.markdown('<h2 class="section-header">üìà Data Upload & Analysis</h2>', unsafe_allow_html=True)

    # Data upload section
    uploaded_file = st.file_uploader(
        "Upload your data file (CSV or Excel)",
        type=['csv', 'xlsx', 'xls']
    )

    if uploaded_file is not None:
        try:
            # Load data
            data_processor = DataProcessor()
            data = data_processor.load_data(uploaded_file)
            st.session_state.data = data

            st.success(f"Data loaded successfully! Shape: {data.shape}")

            # Display data preview
            st.subheader("Data Preview")
            st.dataframe(data.head())

            # Data summary
            st.subheader("Data Summary")
            col1, col2 = st.columns(2)

            with col1:
                st.write("**Basic Information:**")
                st.write(f"- Rows: {data.shape[0]}")
                st.write(f"- Columns: {data.shape[1]}")
                st.write(f"- Missing values: {data.isnull().sum().sum()}")

            with col2:
                st.write("**Column Types:**")
                for col, dtype in data.dtypes.items():
                    st.write(f"- {col}: {dtype}")

            # Statistical analysis section
            if st.session_state.selected_test:
                st.subheader(f"Perform {st.session_state.selected_test}")
                perform_statistical_test(data)
            else:
                st.info("Use the Test Selection Wizard to choose an appropriate test.")

        except Exception as e:
            st.error(f"Error loading data: {str(e)}")

    else:
        # Sample dataset option
        st.subheader("Or try a sample dataset:")
        sample_data_option = st.selectbox(
            "Choose a sample dataset:",
            ["None", "Biological Growth Study", "Gene Expression", "Clinical Trial"]
        )

        if sample_data_option != "None":
            data = load_sample_dataset(sample_data_option)
            st.session_state.data = data
            st.dataframe(data.head())

def perform_statistical_test(data):
    """Perform the selected statistical test"""

    # Column selection
    columns = data.columns.tolist()

    col1, col2 = st.columns(2)
    with col1:
        dependent_var = st.selectbox("Select dependent variable:", columns)
    with col2:
        independent_var = st.selectbox("Select independent variable:", columns)

    if st.button("Run Analysis"):
        try:
            # Initialize test handler
            test_handler = StatisticalTests()
            assumption_checker = AssumptionChecker()
            visualizer = Visualizer()
            interpreter = ResultsInterpreter()

            # Check assumptions
            st.subheader("Assumption Checking")
            assumptions = assumption_checker.check_assumptions(
                data, dependent_var, independent_var, st.session_state.selected_test
            )

            for assumption, result in assumptions.items():
                if result['passed']:
                    st.success(f"‚úì {assumption}: {result['message']}")
                else:
                    st.warning(f"‚ö†Ô∏è {assumption}: {result['message']}")

            # Perform test
            st.subheader("Test Results")
            results = test_handler.perform_test(
                data, dependent_var, independent_var, st.session_state.selected_test
            )

            # Display results
            st.write(f"**Test Statistic:** {results['statistic']:.4f}")
            st.write(f"**P-value:** {results['p_value']:.4f}")
            st.write(f"**Effect Size:** {results.get('effect_size', 'N/A')}")

            # Interpretation
            interpretation = interpreter.interpret_results(results, st.session_state.selected_test)
            st.markdown(f"""
            <div class="info-box">
            <h4>Interpretation:</h4>
            <p>{interpretation}</p>
            </div>
            """, unsafe_allow_html=True)

            # Visualization
            st.subheader("Visualization")
            fig = visualizer.create_plot(data, dependent_var, independent_var, st.session_state.selected_test)
            st.plotly_chart(fig, use_container_width=True)

            # Post-hoc analysis if needed
            if st.session_state.selected_test in ['One-way ANOVA', 'Kruskal-Wallis test'] and results['p_value'] <= 0.05:
                st.subheader("Post-Hoc Analysis")
                st.info("Significant omnibus test detected. Post-hoc analysis recommended.")

                post_hoc_handler = PostHocTests()
                recommendation = post_hoc_handler.recommend_post_hoc_test(
                    st.session_state.selected_test,
                    assumptions_passed=all(a.get('passed', True) for a in assumptions.values())
                )

                st.write(f"**Recommended:** {recommendation['recommended']}")
                st.write(f"**Rationale:** {recommendation['rationale']}")

                if st.button("Perform Post-Hoc Analysis"):
                    post_hoc_results = post_hoc_handler.perform_post_hoc(
                        data, dependent_var, independent_var, recommendation['recommended']
                    )

                    if 'error' not in post_hoc_results:
                        st.success("Post-hoc analysis completed!")
                        st.write(post_hoc_results['interpretation'])

                        # Display results table
                        if 'comparisons' in post_hoc_results:
                            comparisons_df = pd.DataFrame(post_hoc_results['comparisons'])
                            st.dataframe(comparisons_df)
                    else:
                        st.error(post_hoc_results['error'])

            # Report generation
            st.subheader("Generate Report")
            report_generator = ReportGenerator()

            col1, col2, col3 = st.columns(3)
            with col1:
                if st.button("Basic Report"):
                    report = report_generator.generate_report(results, 'basic', interpretation=interpretation)
                    st.session_state.report_content = report['content']

            with col2:
                if st.button("Comprehensive Report"):
                    report = report_generator.generate_report(
                        results, 'comprehensive',
                        assumptions=assumptions,
                        interpretation=interpretation
                    )
                    st.session_state.report_content = report['content']

            with col3:
                if st.button("Publication Report"):
                    report = report_generator.generate_report(results, 'publication')
                    st.session_state.report_content = report['content']

            # Display and download report
            if 'report_content' in st.session_state:
                st.subheader("Generated Report")
                st.markdown(st.session_state.report_content)

                # Download options
                st.subheader("Download Report")
                download_data = report_generator.create_downloadable_report(
                    st.session_state.report_content, 'html'
                )
                st.download_button(
                    label="Download as HTML",
                    data=download_data['content'],
                    file_name=download_data['filename'],
                    mime=download_data['mime_type']
                )

        except Exception as e:
            st.error(f"Error performing analysis: {str(e)}")

def show_educational_content():
    """Display educational content"""

    st.markdown('<h2 class="section-header">üìö Educational Content</h2>', unsafe_allow_html=True)

    topic = st.selectbox(
        "Choose a topic:",
        [
            "Introduction to Statistical Testing",
            "Hypothesis Testing Fundamentals",
            "Choosing the Right Test",
            "Understanding P-values",
            "Effect Sizes and Practical Significance",
            "Common Statistical Mistakes",
            "Regression Analysis: Linear and Logarithmic",
            "Multiple Linear Regression (MLR)",
            "K-Means Clustering"
        ]
    )

    if topic == "Introduction to Statistical Testing":
        show_intro_content()
    elif topic == "Hypothesis Testing Fundamentals":
        show_hypothesis_content()
    elif topic == "Regression Analysis: Linear and Logarithmic":
        show_regression_content()
    elif topic == "Multiple Linear Regression (MLR)":
        show_mlr_content()
    elif topic == "K-Means Clustering":
        show_kmeans_content()
    else:
        st.write(f"Content for '{topic}' coming soon!")

def show_intro_content():
    """Show introduction to statistical testing"""

    st.markdown("""
    ### What is Statistical Testing?

    Statistical testing is a formal procedure for making decisions about populations based on sample data.
    It helps us determine whether observed differences or relationships in our data are likely due to real
    effects or just random variation.

    ### Key Concepts:

    **Population vs. Sample**
    - Population: The entire group you want to study
    - Sample: A subset of the population that you actually measure

    **Null Hypothesis (H‚ÇÄ)**
    - A statement of "no effect" or "no difference"
    - What we assume to be true until proven otherwise

    **Alternative Hypothesis (H‚ÇÅ)**
    - A statement that contradicts the null hypothesis
    - What we want to provide evidence for

    **P-value**
    - The probability of observing data as extreme as ours, assuming H‚ÇÄ is true
    - Helps us decide whether to reject or fail to reject H‚ÇÄ
    """)

def show_hypothesis_content():
    """Show hypothesis testing content"""

    st.markdown("""
    ### The Hypothesis Testing Process

    1. **Formulate Hypotheses**
       - State your null and alternative hypotheses clearly
       - Example: H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ (no difference between group means)

    2. **Choose Significance Level (Œ±)**
       - Usually 0.05 (5%) in biological sciences
       - This is your tolerance for Type I error

    3. **Select Appropriate Test**
       - Based on data type, study design, and assumptions
       - This tool helps you choose!

    4. **Check Assumptions**
       - Most tests have requirements (normality, equal variances, etc.)
       - Use alternative tests if assumptions are violated

    5. **Calculate Test Statistic**
       - Compare your data to what's expected under H‚ÇÄ

    6. **Make Decision**
       - If p ‚â§ Œ±: Reject H‚ÇÄ (statistically significant)
       - If p > Œ±: Fail to reject H‚ÇÄ (not statistically significant)
    """)

def show_regression_content():
    """Show regression analysis educational content"""

    st.markdown("""
    ## üìà Analiza Regresji: Liniowa i Logarytmiczna

    Analiza regresji to jedna z fundamentalnych technik statystycznych. Jej celem jest **modelowanie zale≈ºno≈õci**
    miƒôdzy zmiennymi. Najczƒô≈õciej chcemy zrozumieƒá, jak jedna zmienna (zale≈ºna, $Y$) zmienia siƒô, gdy zmienia
    siƒô inna zmienna (niezale≈ºna, $X$).

    ### Czym jest Regresja Liniowa?

    Regresja liniowa jest najprostszym typem regresji. Zak≈Çada ona, ≈ºe zale≈ºno≈õƒá miƒôdzy zmiennƒÖ $X$ a $Y$
    mo≈ºna opisaƒá za pomocƒÖ **linii prostej**.

    #### Wz√≥r

    Model opisany jest prostym r√≥wnaniem:

    $$
    y = ax + b
    $$

    Gdzie:

    * **$y$** ‚Äì Warto≈õƒá prognozowana (zmienna zale≈ºna).
    * **$x$** ‚Äì Warto≈õƒá zmiennej niezale≈ºnej.
    * **$a$** ‚Äì **Wsp√≥≈Çczynnik nachylenia** (slope). M√≥wi nam, o ile *≈õrednio* zmieni siƒô $y$, je≈õli $x$ wzro≈õnie o jednƒÖ jednostkƒô.
    * **$b$** ‚Äì **Wyraz wolny** (intercept). Jest to punkt przeciƒôcia linii z osiƒÖ $Y$, czyli warto≈õƒá $y$, gdy $x$ wynosi 0.

    #### Jak siƒô jƒÖ liczy?

    NajpopularniejszƒÖ metodƒÖ jest **Metoda Najmniejszych Kwadrat√≥w (Ordinary Least Squares - OLS)**.
    Komputer szuka takiej linii (czyli takich warto≈õci $a$ i $b$), kt√≥ra minimalizuje sumƒô kwadrat√≥w odleg≈Ço≈õci
    (tzw. "b≈Çƒôd√≥w" lub "rezydu√≥w") miƒôdzy rzeczywistymi punktami danych a liniƒÖ regresji.

    #### Kiedy jej u≈ºywaƒá?

    * Gdy na wykresie punktowym dane wydajƒÖ siƒô uk≈Çadaƒá wzd≈Çu≈º linii prostej.
    * Gdy zak≈Çadamy sta≈Çe tempo zmiany (np. koszt wyprodukowania 10 sztuk jest 10 razy wiƒôkszy ni≈º 1 sztuki).
    * Jako model bazowy do por√≥wnania z bardziej skomplikowanymi modelami.

    ---

    ### Czym jest Regresja Logarytmiczna?

    Regresja logarytmiczna jest modelem krzywoliniowym. Jest idealna do opisywania sytuacji, w kt√≥rych
    zale≈ºno≈õƒá **szybko ro≈õnie na poczƒÖtku, a nastƒôpnie zwalnia** (lub nasyca siƒô).

    #### Wz√≥r

    Model opisany jest r√≥wnaniem:

    $$
    y = a \\cdot \\ln(x) + b
    $$

    Gdzie:

    * **$y$**, **$a$**, **$b$** ‚Äì MajƒÖ podobne znaczenie jak w regresji liniowej.
    * **$\\ln(x)$** ‚Äì **Logarytm naturalny** ze zmiennej $x$.

    **Wa≈ºna uwaga:** Model ten mo≈ºna stosowaƒá tylko wtedy, gdy warto≈õci zmiennej niezale≈ºnej $X$ sƒÖ
    **dodatnie** ($x > 0$), poniewa≈º logarytm z zera lub liczb ujemnych jest niezdefiniowany.

    #### Jak siƒô jƒÖ liczy?

    Najczƒô≈õciej sprowadza siƒô to do prostego triku:

    1. Tworzymy nowƒÖ zmiennƒÖ, $X' = \\ln(X)$.
    2. Wykonujemy **regresjƒô liniowƒÖ** na danych $(X', Y)$.
       Model, kt√≥ry otrzymujemy, to $y = a \\cdot X' + b$, co po podstawieniu $X'$ daje nam $y = a \\cdot \\ln(x) + b$.

    #### Kiedy jej u≈ºywaƒá?

    * Gdy obserwujemy **prawo malejƒÖcych przychod√≥w**. Na przyk≈Çad:
        * Wp≈Çyw wydatk√≥w na reklamƒô na sprzeda≈º (pierwsza wydana z≈Çot√≥wka przynosi du≈ºy zwrot, ale milionowa ju≈º znacznie mniejszy).
        * Wp≈Çyw liczby godzin nauki na wynik egzaminu (przej≈õcie z 0 na 2 godziny daje du≈ºy skok; przej≈õcie z 10 na 12 godzin ‚Äì niewielki).
    * Gdy tempo wzrostu $Y$ maleje wraz ze wzrostem $X$.

    ---

    ### Jak oceniƒá, kt√≥ry model jest lepszy?

    Po dopasowaniu obu modeli do tych samych danych, musimy zdecydowaƒá, kt√≥ry z nich jest lepszy.
    U≈ºywamy do tego dw√≥ch kluczowych metryk:

    #### 1. R-kwadrat (R¬≤) ‚Äì Wsp√≥≈Çczynnik Determinacji

    * **Co mierzy:** Jak dobrze model (linia lub krzywa) **wyja≈õnia zmienno≈õƒá** w danych.
    * **Interpretacja:** Jest to warto≈õƒá od 0 do 1 (lub 0% do 100%).
        * R¬≤ = 0.85 oznacza, ≈ºe 85% zmienno≈õci w $Y$ jest wyja≈õniane przez zmiennƒÖ $X$ za pomocƒÖ naszego modelu.
    * **Wyb√≥r:** **Im wy≈ºszy R¬≤, tym (zazwyczaj) lepszy model.** Lepsze dopasowanie do danych.

    #### 2. B≈ÇƒÖd ≈öredniokwadratowy (Mean Squared Error - MSE)

    * **Co mierzy:** ≈öredniƒÖ kwadrat√≥w b≈Çƒôd√≥w (r√≥≈ºnic miƒôdzy warto≈õciƒÖ rzeczywistƒÖ $y$ a prognozowanƒÖ $\\hat{y}$).
    * **Interpretacja:** Jest to miara b≈Çƒôdu prognozy. Poniewa≈º b≈Çƒôdy sƒÖ podnoszone do kwadratu, metryka ta
      bardzo **mocno "karze" du≈ºe b≈Çƒôdy**.
    * **Wyb√≥r:** **Im ni≈ºszy MSE, tym lepszy model.** Oznacza to, ≈ºe prognozy modelu sƒÖ ≈õrednio bli≈ºsze prawdy.

    #### Wnioskowanie:

    Najczƒô≈õciej szukamy modelu, kt√≥ry ma **jednocze≈õnie wysoki R¬≤ i niski MSE**.

    ### Problem Overfittingu (Przeuczenia)

    Overfitting to jeden z najwiƒôkszych problem√≥w w modelowaniu.

    * **Definicja:** Zjawisko, w kt√≥rym model jest **zbyt skomplikowany** i zamiast uczyƒá siƒô og√≥lnego trendu
      w danych, zaczyna "wkuwaƒá na pamiƒôƒá" dane treningowe, ≈ÇƒÖcznie z przypadkowym szumem.
    * **Skutek:** Taki model ma fantastyczne metryki (np. R¬≤ bliskie 1.0) na danych, na kt√≥rych by≈Ç uczony,
      ale kompletnie nie potrafi przewidywaƒá nowych, nieznanych mu danych.
    * **Jak siƒô chroniƒá:** W przypadku prostych modeli (jak regresja liniowa czy logarytmiczna z jednƒÖ zmiennƒÖ)
      ryzyko jest bardzo ma≈Çe. Problem pojawia siƒô przy modelach bardzo z≈Ço≈ºonych (np. wielomiany wysokiego stopnia,
      g≈Çƒôbokie sieci neuronowe).
    * **Podstawowa zasada:** Zawsze nale≈ºy dƒÖ≈ºyƒá do modelu **mo≈ºliwie najprostszego**, kt√≥ry wciƒÖ≈º dobrze wyja≈õnia
      dane (tzw. "Zasada Oszczƒôdno≈õci" lub "Brzytwa Ockhama").

    ---

    ### üí° Podsumowanie

    * **Regresja liniowa** jest odpowiednia dla zale≈ºno≈õci liniowych (sta≈Çe tempo zmiany).
    * **Regresja logarytmiczna** jest lepsza dla zale≈ºno≈õci, kt√≥re zwalniajƒÖ wraz ze wzrostem X (malejƒÖce przychody).
    * Por√≥wnujemy modele u≈ºywajƒÖc **R¬≤** (wy≈ºsze = lepsze) i **MSE** (ni≈ºsze = lepsze).
    * Proste modele minimalizujƒÖ ryzyko przeuczenia (overfitting).
    * Zawsze nale≈ºy rozwa≈ºyƒá praktyczne znaczenie wynik√≥w, nie tylko statystyczne dopasowanie.

    **Zachƒôcamy do eksperymentowania z modu≈Çem Analizy Regresji, aby zobaczyƒá te koncepcje w praktyce!**
    """)

def show_mlr_content():
    """Show Multiple Linear Regression educational content"""

    st.markdown("""
    ## üìä Wielokrotna Regresja Liniowa (Multiple Linear Regression - MLR)

    Wielokrotna Regresja Liniowa (MLR) to rozszerzenie Regresji Liniowej Prostej. Zamiast u≈ºywaƒá tylko jednej zmiennej $X$ do przewidywania $Y$, MLR pozwala nam u≈ºywaƒá **wielu zmiennych $X$ jednocze≈õnie**.

    Jest to jedna z najczƒô≈õciej u≈ºywanych technik w statystyce i data science, pozwalajƒÖca na budowanie bardziej z≈Ço≈ºonych i dok≈Çadniejszych modeli prognozujƒÖcych.

    ### Wz√≥r

    Podczas gdy regresja prosta mia≈Ça wz√≥r $y = ax + b$, regresja wielokrotna ma postaƒá:

    $$
    y = b_0 + a_1x_1 + a_2x_2 + \\dots + a_kx_k
    $$

    Gdzie:

    * **$y$** ‚Äì Warto≈õƒá prognozowana (zmienna zale≈ºna).
    * **$x_1, x_2, \\dots, x_k$** ‚Äì Zmienne niezale≈ºne (predyktory).
    * **$b_0$** ‚Äì **Wyraz wolny** (intercept). Warto≈õƒá $y$, gdy wszystkie zmienne $x$ sƒÖ r√≥wne zero.
    * **$a_1, a_2, \\dots, a_k$** ‚Äì **Wsp√≥≈Çczynniki** regresji.

    ### Jak interpretowaƒá wsp√≥≈Çczynniki (to kluczowe!)

    Interpretacja wsp√≥≈Çczynnika $a$ w MLR jest inna ni≈º w regresji prostej.

    > Wsp√≥≈Çczynnik **$a_1$** m√≥wi nam, o ile *≈õrednio* zmieni siƒô $y$, je≈õli $x_1$ wzro≈õnie o jednƒÖ jednostkƒô, **przy za≈Ço≈ºeniu, ≈ºe wszystkie pozosta≈Çe zmienne ($x_2, \\dots, x_k$) pozostajƒÖ bez zmian**.

    Jest to miara "czystego" wp≈Çywu danej zmiennej $x_1$ na $y$, po wyizolowaniu wp≈Çywu pozosta≈Çych zmiennych uwzglƒôdnionych w modelu.

    **Przyk≈Çad:** Model ceny mieszkania:
    `Cena = 50000 + (7000 * Liczba_Pokoi) + (300 * Powierzchnia_m2)`

    * Wsp√≥≈Çczynnik `7000` oznacza, ≈ºe (wed≈Çug modelu) dodanie jednego pokoju podnosi cenƒô o 7000 z≈Ç, **przy tej samej powierzchni**.
    * Wsp√≥≈Çczynnik `300` oznacza, ≈ºe ka≈ºdy dodatkowy m¬≤ podnosi cenƒô o 300 z≈Ç, **przy tej samej liczbie pokoi**.

    ---

    ### Metryki Oceny: R¬≤ vs. R¬≤ Skorygowany

    W regresji wielokrotnej pojawia siƒô nowy, wa≈ºniejszy wska≈∫nik.

    #### R-kwadrat (R¬≤)

    M√≥wi, jaki procent zmienno≈õci $Y$ jest wyja≈õniany przez *wszystkie* zmienne $X$ w modelu.

    * **Problem:** Warto≈õƒá R¬≤ **zawsze ro≈õnie (lub pozostaje taka sama)**, gdy dodajemy do modelu nowƒÖ zmiennƒÖ $X$, nawet je≈õli ta zmienna jest kompletnie losowa i nie ma ≈ºadnego zwiƒÖzku z $Y$. To zachƒôca do budowania przeuczonych (overfitted) modeli.

    #### R-kwadrat Skorygowany (Adjusted R¬≤)

    To jest ulepszona wersja R¬≤, kt√≥ra rozwiƒÖzuje ten problem.

    * **Co robi:** "Karze" model za posiadanie wielu zmiennych. R¬≤ Skorygowany ro≈õnie tylko wtedy, gdy dodana nowa zmienna wnosi do modelu **istotnƒÖ** moc wyja≈õniajƒÖcƒÖ.
    * **Interpretacja:** Je≈õli dodasz do modelu nowƒÖ zmiennƒÖ $X$ i R¬≤ Skorygowany spadnie, oznacza to, ≈ºe ta zmienna jest zbƒôdna i pogarsza jako≈õƒá modelu (prawdopodobnie dodaje wiƒôcej szumu ni≈º sygna≈Çu).

    **Wniosek: Przy Wielokrotnej Regresji Liniowej zawsze u≈ºywaj R-kwadrat Skorygowanego do oceny i por√≥wnywania modeli.**

    ---

    ### Najwiƒôksze Zagro≈ºenia w MLR

    #### 1. Overfitting (Przeuczenie)

    * **Problem:** Dodanie zbyt wielu zmiennych $X$, szczeg√≥lnie przy ma≈Çej ilo≈õci danych. Model zaczyna "uczyƒá siƒô na pamiƒôƒá" szumu w danych, zamiast og√≥lnego trendu.
    * **Skutek:** Model bƒôdzie mia≈Ç ≈õwietny R¬≤ na danych treningowych, ale fatalnie poradzi sobie z prognozowaniem nowych, nieznanych danych.
    * **Obrona:** U≈ºywaj R¬≤ Skorygowanego; stosuj Zasadƒô Oszczƒôdno≈õci (wybieraj najprostszy model, kt√≥ry dobrze dzia≈Ça).

    #### 2. Multikolinearno≈õƒá (Wsp√≥≈Çliniowo≈õƒá)

    * **Problem:** Sytuacja, w kt√≥rej dwie lub wiƒôcej zmiennych $X$ sƒÖ ze sobƒÖ silnie skorelowane (np. `waga_w_kg` i `waga_w_funtach`, albo `wzrost` i `d≈Çugo≈õƒá_nogi`).
    * **Skutek:** Algorytm regresji "g≈Çupieje". Nie wie, kt√≥rej ze skorelowanych zmiennych przypisaƒá wp≈Çyw na $Y$. Powoduje to, ≈ºe:
        * Wsp√≥≈Çczynniki ($a_1, a_2$) stajƒÖ siƒô bardzo niestabilne.
        * MogƒÖ mieƒá absurdalne warto≈õci lub znaki (np. model m√≥wi, ≈ºe wzrost *obni≈ºa* wagƒô, bo ≈∫le rozdzieli≈Ç wp≈Çyw).
    * **Obrona:** Sprawd≈∫ korelacjƒô miƒôdzy zmiennymi $X$ *przed* zbudowaniem modelu. Je≈õli dwie zmienne majƒÖ korelacjƒô > 0.8 (lub < -0.8), rozwa≈º usuniƒôcie jednej z nich.

    ---

    ### üí° Podsumowanie

    * **Wielokrotna Regresja Liniowa** pozwala modelowaƒá wp≈Çyw wielu zmiennych $X$ na $Y$ jednocze≈õnie.
    * **Wsp√≥≈Çczynniki** pokazujƒÖ "czysty" wp≈Çyw ka≈ºdej zmiennej, po kontroli pozosta≈Çych.
    * **R¬≤ Skorygowany** jest lepszƒÖ metrykƒÖ ni≈º zwyk≈Çy R¬≤, poniewa≈º karze za zbƒôdne zmienne.
    * **Overfitting** jest wiƒôkszym zagro≈ºeniem ni≈º w regresji prostej ‚Äì uwa≈ºaj na dodawanie zbyt wielu zmiennych.
    * **Multikolinearno≈õƒá** miƒôdzy predyktorami mo≈ºe prowadziƒá do niestabilnych i mylƒÖcych wynik√≥w.
    * Zawsze dƒÖ≈º do **najprostszego modelu**, kt√≥ry wystarczajƒÖco dobrze wyja≈õnia dane (Zasada Oszczƒôdno≈õci).

    **Zachƒôcamy do eksperymentowania z modu≈Çem Analizy Regresji, aby zobaczyƒá te koncepcje w praktyce!**
    """)

def show_kmeans_content():
    """Show K-Means clustering educational content"""

    st.markdown("""
    ## üí† Klastrowanie K-Means (Grupowanie MetodƒÖ K-≈örednich)

    K-Means to jeden z najpopularniejszych algorytm√≥w **uczenia nienadzorowanego**. Jego celem jest automatyczne podzielenie zbioru danych na $K$ odrƒôbnych grup (klastr√≥w), gdzie punkty wewnƒÖtrz jednego klastra sƒÖ do siebie jak najbardziej podobne, a punkty miƒôdzy r√≥≈ºnymi klastrami ‚Äì jak najmniej.

    ### Jak Dzia≈Ça Algorytm K-Means?

    Algorytm dzia≈Ça iteracyjnie, pr√≥bujƒÖc znale≈∫ƒá "≈õrodki" (centroidy) dla $K$ grup.

    1.  **Krok 1: Wyb√≥r $K$**
        U≈ºytkownik musi na poczƒÖtku **zdecydowaƒá**, na ile grup ($K$) chce podzieliƒá dane. (Patrz poni≈ºej, jak wybraƒá $K$).
    2.  **Krok 2: Inicjalizacja**
        Algorytm losowo (lub "inteligentnie" dziƒôki metodzie `k-means++`) umieszcza $K$ centroid√≥w (punkt√≥w centralnych) w przestrzeni danych.
    3.  **Krok 3: Przypisanie**
        Ka≈ºdy punkt danych jest przypisywany do **najbli≈ºszego** mu centroidu (zazwyczaj na podstawie odleg≈Ço≈õci euklidesowej).
    4.  **Krok 4: Aktualizacja**
        Po przypisaniu wszystkich punkt√≥w, centroidy sƒÖ **przesuwane**. NowƒÖ lokalizacjƒÖ ka≈ºdego centroidu jest **≈õrednia arytmetyczna** wszystkich punkt√≥w, kt√≥re zosta≈Çy do niego przypisane.
    5.  **Krok 5: Powt√≥rzenie**
        Kroki 3 i 4 sƒÖ powtarzane a≈º do **konwergencji** ‚Äì czyli do momentu, gdy centroidy przestanƒÖ siƒô znaczƒÖco przemieszczaƒá (klastry siƒô ustabilizujƒÖ).

    ---

    ### Metody Statystyczne: "Jak wybraƒá K?"

    To najwiƒôksze wyzwanie w K-Means. Nie ma jednej "poprawnej" odpowiedzi, ale u≈ºywamy metod statystycznych, aby oszacowaƒá dobrƒÖ warto≈õƒá $K$.

    #### 1. Metoda ≈Åokcia (Elbow Method)

      * **Co mierzy:** **Inercjƒô (WCSS)**, czyli sumƒô kwadrat√≥w odleg≈Ço≈õci ka≈ºdego punktu od jego centroidu. M√≥wiƒÖc pro≈õciej: jak bardzo "≈õcis≈Çe" sƒÖ klastry.
      * **Jak to dzia≈Ça:** Uruchamiamy K-Means dla r√≥≈ºnych warto≈õci $K$ (np. od 2 do 10) i liczymy inercjƒô dla ka≈ºdej z nich.
      * **Interpretacja:**
          * Im wiƒôcej klastr√≥w ($K$), tym mniejsza bƒôdzie inercja (bo klastry sƒÖ mniejsze i cia≈õniejsze).
          * Rysujemy wykres $K$ vs. Inercja.
          * Szukamy punktu **"za≈Çamania" (≈Çokcia)** ‚Äì miejsca, w kt√≥rym linia przestaje gwa≈Çtownie opadaƒá. Jest to punkt, w kt√≥rym dodanie kolejnego klastra nie przynosi ju≈º du≈ºej korzy≈õci (nie zmniejsza znaczƒÖco inercji).

    #### 2. Analiza Sylwetkowa (Silhouette Analysis)

      * **Co mierzy:** **Wsp√≥≈Çczynnik Sylwetkowy (Silhouette Score)**. Jest to miara bardziej zaawansowana, kt√≥ra ocenia dwie rzeczy jednocze≈õnie:
        1.  **Sp√≥jno≈õƒá (Cohesion):** Jak blisko punkty sƒÖ do innych punkt√≥w w tym samym klastrze?
        2.  **Separacjƒô (Separation):** Jak daleko punkty sƒÖ od punkt√≥w w *innych* klastrach?
      * **Jak to dzia≈Ça:** Wynik jest obliczany dla ka≈ºdego punktu i mie≈õci siƒô w zakresie od -1 do 1.
          * **+1:** Idealnie. Punkt jest daleko od sƒÖsiednich klastr√≥w i blisko swoich.
          * **0:** Punkt jest na granicy dw√≥ch klastr√≥w (nak≈Çadanie siƒô).
          * **-1:** ≈πle. Punkt jest prawdopodobnie przypisany do z≈Çego klastra.
      * **Interpretacja:**
          * Uruchamiamy K-Means dla r√≥≈ºnych $K$ i liczymy *≈õredni* Wsp√≥≈Çczynnik Sylwetkowy dla wszystkich punkt√≥w.
          * Rysujemy wykres $K$ vs. ≈öredni Silhouette Score.
          * W przeciwie≈Ñstwie do Metody ≈Åokcia, tutaj **szukamy maksimum (szczytu)**. Najwy≈ºszy wynik wskazuje na $K$, kt√≥re daje najbardziej sp√≥jne i najlepiej odseparowane klastry.

    ---

    ### Inne "Metody" i Wymagania K-Means

    Aby K-Means zadzia≈Ça≈Ço poprawnie, nie wystarczy tylko wybraƒá $K$. Kluczowe sƒÖ te≈º poni≈ºsze "metody" (techniki).

    #### 1. Metoda: Standaryzacja Danych

      * **Problem:** Algorytm K-Means opiera siƒô na **odleg≈Ço≈õci**. Je≈õli masz cechy o r√≥≈ºnych skalach (np. `Wiek` [0-100] i `Zarobki` [3 000 - 50 000]), cecha o wiƒôkszej skali (`Zarobki`) ca≈Çkowicie zdominuje obliczenia odleg≈Ço≈õci. Algorytm praktycznie zignoruje `Wiek`.
      * **RozwiƒÖzanie (Metoda):** **Standaryzacja** (np. `StandardScaler` w Scikit-learn).
      * **Co robi:** Przekszta≈Çca wszystkie cechy tak, aby mia≈Çy ≈õredniƒÖ r√≥wnƒÖ 0 i odchylenie standardowe r√≥wne 1. To sprawia, ≈ºe ka≈ºda cecha ma "r√≥wnƒÖ wagƒô" w algorytmie.
      * **Wniosek:** **Prawie zawsze powiniene≈õ standaryzowaƒá dane przed u≈ºyciem K-Means.**

    #### 2. Metoda: Inicjalizacja (Problem Lokalne Minimum)

      * **Problem:** Wynik K-Means mo≈ºe zale≈ºeƒá od tego, gdzie **na poczƒÖtku** zosta≈Çy umieszczone centroidy (Krok 2). Z≈Çy poczƒÖtkowy wyb√≥r mo≈ºe uwiƒôziƒá algorytm w "lokalnym minimum" ‚Äì znajdzie on klastry, ale nie bƒôdƒÖ one optymalne.
      * **RozwiƒÖzanie (Metoda 1): `n_init`**
          * Uruchamiamy algorytm K-Means **wiele razy** (np. `n_init=10`) z r√≥≈ºnymi losowymi punktami startowymi.
          * Jako ostateczny wynik wybierany jest ten przebieg, kt√≥ry da≈Ç najni≈ºszƒÖ inercjƒô (WCSS).
      * **RozwiƒÖzanie (Metoda 2): `init='k-means++'`**
          * To domy≈õlna metoda inicjalizacji w Scikit-learn.
          * Zamiast umieszczaƒá centroidy w pe≈Çni losowo, `k-means++` robi to "inteligentnie" ‚Äì stara siƒô umie≈õciƒá poczƒÖtkowe centroidy daleko od siebie. ZnaczƒÖco zwiƒôksza to szansƒô na znalezienie optymalnych klastr√≥w i przyspiesza konwergencjƒô.

    ---

    ### üí° Podsumowanie

    * **K-Means** to algorytm uczenia nienadzorowanego do grupowania danych w klastry.
    * Wymaga wybrania liczby klastr√≥w **K** z g√≥ry.
    * **Metoda ≈Åokcia** pomaga znale≈∫ƒá K poprzez identyfikacjƒô punktu, w kt√≥rym dodanie kolejnego klastra nie przynosi znaczƒÖcej redukcji inercji.
    * **Analiza Sylwetkowa** mierzy jako≈õƒá klastr√≥w (sp√≥jno≈õƒá i separacjƒô) ‚Äì szukamy K z najwy≈ºszym wynikiem.
    * **Standaryzacja danych** jest kluczowa, aby zapewniƒá r√≥wnƒÖ wagƒô wszystkim cechom.
    * U≈ºywamy **k-means++** i **n_init** aby uniknƒÖƒá lokalnych minim√≥w i znale≈∫ƒá optymalne rozwiƒÖzanie.

    **Zachƒôcamy do eksperymentowania z modu≈Çem Klastrowania K-Means, aby zobaczyƒá te koncepcje w praktyce!**
    """)

def show_test_library():
    """Display the test library"""

    st.markdown('<h2 class="section-header">üìñ Test Library</h2>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <p>Comprehensive reference guide for all statistical tests available in the application.</p>
    </div>
    """, unsafe_allow_html=True)

    test_category = st.selectbox(
        "Choose a category:",
        [
            "Comparing Two Groups",
            "Comparing Multiple Groups",
            "Relationships Between Variables",
            "Categorical Data Analysis",
            "Advanced Multivariate Tests",
            "Post-Hoc Tests",
            "Power Analysis"
        ]
    )

    if test_category == "Comparing Two Groups":
        show_two_group_tests()
    elif test_category == "Comparing Multiple Groups":
        show_multiple_group_tests()
    elif test_category == "Relationships Between Variables":
        show_relationship_tests()
    elif test_category == "Categorical Data Analysis":
        show_categorical_tests()
    elif test_category == "Advanced Multivariate Tests":
        show_advanced_tests()
    elif test_category == "Post-Hoc Tests":
        show_posthoc_tests()
    elif test_category == "Power Analysis":
        show_power_analysis_info()

def show_two_group_tests():
    """Show information about two-group tests"""

    st.markdown("### Parametric Tests for Two Groups")

    parametric_tests = {
        "Independent t-test": {
            "purpose": "Compare means of two independent groups when data are normally distributed",
            "assumptions": ["Normality in both groups", "Equal variances (homoscedasticity)", "Independence of observations"],
            "when_to_use": "When you have two separate groups and want to compare their means",
            "example": "Comparing average blood pressure between patients receiving drug A vs. drug B",
            "effect_size": "Cohen's d",
            "interpretation": "Tests if the difference between group means is statistically significant",
            "alternatives": "Use Welch's t-test if variances are unequal, or Mann-Whitney U if normality is violated"
        },
        "Welch's t-test": {
            "purpose": "Compare means of two independent groups when variances are unequal",
            "assumptions": ["Normality in both groups", "Independence of observations", "Unequal variances allowed"],
            "when_to_use": "When groups have significantly different variances (failed Levene's test)",
            "example": "Comparing gene expression between healthy and diseased tissue (different variability)",
            "effect_size": "Cohen's d",
            "interpretation": "Adjusts degrees of freedom to account for unequal variances",
            "alternatives": "Use Mann-Whitney U test if normality assumptions are also violated"
        },
        "Paired t-test": {
            "purpose": "Compare means of two related measurements on the same subjects",
            "assumptions": ["Normality of differences", "Independence of paired differences"],
            "when_to_use": "Before-after studies, matched pairs, or repeated measures on same subjects",
            "example": "Comparing blood pressure before and after treatment in the same patients",
            "effect_size": "Cohen's d for paired data",
            "interpretation": "Tests if the mean difference between paired observations is significantly different from zero",
            "alternatives": "Use Wilcoxon signed-rank test if differences are not normally distributed"
        }
    }

    for test_name, info in parametric_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

    st.markdown("### Non-Parametric Tests for Two Groups")

    nonparametric_tests = {
        "Mann-Whitney U test": {
            "purpose": "Compare distributions of two independent groups without assuming normality",
            "assumptions": ["Independence of observations", "Ordinal or continuous data", "Similar distribution shapes for median comparison"],
            "when_to_use": "When data are not normally distributed, ordinal, or have outliers",
            "example": "Comparing patient satisfaction scores (1-10 scale) between two hospitals",
            "effect_size": "Rank-biserial correlation (r)",
            "interpretation": "Tests if one group tends to have higher values than the other",
            "alternatives": "Use independent t-test if normality assumptions are met"
        },
        "Wilcoxon signed-rank test": {
            "purpose": "Compare paired observations when differences are not normally distributed",
            "assumptions": ["Paired observations", "Continuous data", "Symmetric distribution of differences"],
            "when_to_use": "Paired data where differences violate normality assumption",
            "example": "Comparing pain scores before and after treatment when data are skewed",
            "effect_size": "Matched pairs rank-biserial correlation",
            "interpretation": "Tests if the median difference between pairs is significantly different from zero",
            "alternatives": "Use paired t-test if differences are normally distributed"
        }
    }

    for test_name, info in nonparametric_tests.items():
        with st.expander(f"üìà {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

def show_multiple_group_tests():
    """Show information about multiple group tests"""

    st.markdown("### Parametric Tests for Multiple Groups")

    parametric_tests = {
        "One-way ANOVA": {
            "purpose": "Compare means across three or more independent groups",
            "assumptions": ["Normality in each group", "Equal variances across groups", "Independence of observations"],
            "when_to_use": "Comparing means of 3+ independent groups",
            "example": "Comparing effectiveness of 4 different fertilizers on plant growth",
            "effect_size": "Eta-squared (Œ∑¬≤) or partial eta-squared",
            "interpretation": "Tests if at least one group mean differs from the others (omnibus test)",
            "follow_up": "Post-hoc tests (Tukey's HSD) needed to identify which groups differ",
            "alternatives": "Use Kruskal-Wallis test if assumptions are violated"
        },
        "Repeated measures ANOVA": {
            "purpose": "Compare means across three or more related measurements",
            "assumptions": ["Normality within each condition", "Sphericity (equal variances of differences)", "Independence of subjects"],
            "when_to_use": "Same subjects measured at multiple time points or conditions",
            "example": "Measuring blood pressure at baseline, 1 month, 3 months, and 6 months",
            "effect_size": "Partial eta-squared",
            "interpretation": "Tests if means change significantly across time/conditions",
            "follow_up": "Pairwise comparisons with Bonferroni correction",
            "alternatives": "Use Friedman test if assumptions are violated"
        },
        "Two-way ANOVA": {
            "purpose": "Analyze effects of two factors and their interaction simultaneously",
            "assumptions": ["Normality in each cell", "Equal variances across all cells", "Independence of observations"],
            "when_to_use": "Two categorical independent variables (factorial design)",
            "example": "Testing effects of drug type (A, B, C) and dosage (low, high) on recovery time",
            "effect_size": "Partial eta-squared for each effect",
            "interpretation": "Tests main effects of each factor and their interaction",
            "follow_up": "Simple effects analysis if interaction is significant",
            "alternatives": "Use non-parametric alternatives or transform data"
        }
    }

    for test_name, info in parametric_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Follow-up:** {info['follow_up']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

    st.markdown("### Non-Parametric Tests for Multiple Groups")

    nonparametric_tests = {
        "Kruskal-Wallis test": {
            "purpose": "Compare distributions across three or more independent groups",
            "assumptions": ["Independence of observations", "Ordinal or continuous data", "Similar distribution shapes"],
            "when_to_use": "Multiple independent groups with non-normal data or ordinal scales",
            "example": "Comparing patient satisfaction ratings across 5 different clinics",
            "effect_size": "Epsilon-squared (Œµ¬≤)",
            "interpretation": "Tests if at least one group has a different distribution",
            "follow_up": "Dunn's test for pairwise comparisons",
            "alternatives": "Use one-way ANOVA if normality assumptions are met"
        },
        "Friedman test": {
            "purpose": "Compare distributions across three or more related measurements",
            "assumptions": ["Related observations", "Ordinal or continuous data", "No distributional assumptions"],
            "when_to_use": "Multiple related measurements with non-normal data",
            "example": "Comparing taste ratings for 4 food samples rated by the same judges",
            "effect_size": "Kendall's W (coefficient of concordance)",
            "interpretation": "Tests if distributions differ across repeated measurements",
            "follow_up": "Pairwise Wilcoxon tests with Bonferroni correction",
            "alternatives": "Use repeated measures ANOVA if assumptions are met"
        }
    }

    for test_name, info in nonparametric_tests.items():
        with st.expander(f"üìà {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Follow-up:** {info['follow_up']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

def show_relationship_tests():
    """Show information about relationship tests"""

    st.markdown("### Correlation Analysis")

    correlation_tests = {
        "Pearson correlation": {
            "purpose": "Measure the strength and direction of linear relationship between two continuous variables",
            "assumptions": ["Linear relationship", "Normality of both variables", "Homoscedasticity", "Independence"],
            "when_to_use": "Two continuous variables with suspected linear relationship",
            "example": "Correlation between height and weight in adults",
            "effect_size": "Correlation coefficient (r)",
            "interpretation": "r = -1 (perfect negative), r = 0 (no linear relationship), r = +1 (perfect positive)",
            "range": "r ranges from -1 to +1",
            "alternatives": "Use Spearman correlation for non-linear monotonic relationships"
        },
        "Spearman correlation": {
            "purpose": "Measure the strength and direction of monotonic relationship between two variables",
            "assumptions": ["Monotonic relationship", "Ordinal or continuous data", "Independence"],
            "when_to_use": "Non-linear but monotonic relationships, ordinal data, or outliers present",
            "example": "Correlation between education level (ordinal) and income",
            "effect_size": "Spearman's rho (œÅ)",
            "interpretation": "œÅ = -1 (perfect negative monotonic), œÅ = 0 (no monotonic relationship), œÅ = +1 (perfect positive monotonic)",
            "range": "œÅ ranges from -1 to +1",
            "alternatives": "Use Pearson correlation if linear relationship and normality assumptions are met"
        }
    }

    for test_name, info in correlation_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
                st.write(f"**Range:** {info['range']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

    st.markdown("### Regression Analysis")

    regression_tests = {
        "Linear regression": {
            "purpose": "Model and predict a continuous outcome from one or more predictor variables",
            "assumptions": ["Linear relationship", "Independence of residuals", "Normality of residuals", "Homoscedasticity of residuals"],
            "when_to_use": "Predicting continuous outcomes, identifying significant predictors",
            "example": "Predicting house prices from size, location, and age",
            "effect_size": "R-squared (R¬≤) - proportion of variance explained",
            "interpretation": "Slope coefficients show change in outcome per unit change in predictor",
            "diagnostics": "Check residual plots, Q-Q plots, and leverage points",
            "alternatives": "Use non-linear regression, transformation, or robust regression"
        },
        "Logistic regression": {
            "purpose": "Model and predict binary outcomes from one or more predictor variables",
            "assumptions": ["Binary outcome", "Independence of observations", "Linear relationship between logit and predictors"],
            "when_to_use": "Predicting binary outcomes (success/failure, disease/healthy)",
            "example": "Predicting disease risk from age, gender, and biomarker levels",
            "effect_size": "Pseudo R-squared, odds ratios",
            "interpretation": "Odds ratios show multiplicative change in odds per unit change in predictor",
            "diagnostics": "Check classification accuracy, ROC curves, and residual deviance",
            "alternatives": "Use discriminant analysis or machine learning methods"
        }
    }

    for test_name, info in regression_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Diagnostics:** {info['diagnostics']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

def show_categorical_tests():
    """Show information about categorical data tests"""

    st.markdown("### Tests for Independence")

    independence_tests = {
        "Chi-squared test": {
            "purpose": "Test for association between two categorical variables",
            "assumptions": ["Independence of observations", "Expected frequencies ‚â• 5 in each cell", "Mutually exclusive categories"],
            "when_to_use": "Two categorical variables with adequate sample sizes",
            "example": "Testing association between smoking status and lung cancer",
            "effect_size": "Cram√©r's V",
            "interpretation": "Tests if distribution of one variable differs across levels of another",
            "limitations": "Sensitive to sample size, doesn't indicate direction of association",
            "alternatives": "Use Fisher's exact test for small expected frequencies"
        },
        "Fisher's exact test": {
            "purpose": "Test for association in 2√ó2 contingency tables with small sample sizes",
            "assumptions": ["Independence of observations", "2√ó2 contingency table", "Fixed marginal totals"],
            "when_to_use": "Small sample sizes where chi-squared assumptions are violated",
            "example": "Testing association between treatment and outcome in small clinical trial",
            "effect_size": "Odds ratio",
            "interpretation": "Provides exact p-value for association in 2√ó2 tables",
            "limitations": "Limited to 2√ó2 tables, computationally intensive for large samples",
            "alternatives": "Use chi-squared test for larger samples"
        }
    }

    for test_name, info in independence_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Limitations:** {info['limitations']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

    st.markdown("### Tests for Paired Categorical Data")

    paired_tests = {
        "McNemar's test": {
            "purpose": "Test for change in proportions in paired binary data",
            "assumptions": ["Paired binary observations", "Independence of pairs", "Dichotomous outcome"],
            "when_to_use": "Before-after studies with binary outcomes, matched case-control studies",
            "example": "Testing if training program changes pass/fail rates in same students",
            "effect_size": "Odds ratio for change",
            "interpretation": "Tests if probability of success changes between paired conditions",
            "focus": "Only considers discordant pairs (those who changed)",
            "alternatives": "Use paired t-test for continuous outcomes"
        },
        "Cochran's Q test": {
            "purpose": "Test for change in proportions across multiple related measurements",
            "assumptions": ["Related binary observations", "Independence of subjects", "3+ time points or conditions"],
            "when_to_use": "Multiple repeated binary measurements on same subjects",
            "example": "Testing if success rates change across 4 quarters in same companies",
            "effect_size": "Effect size depends on specific implementation",
            "interpretation": "Tests if proportion of successes differs across repeated measurements",
            "follow_up": "Pairwise McNemar tests with correction for multiple comparisons",
            "alternatives": "Use repeated measures ANOVA for continuous outcomes"
        }
    }

    for test_name, info in paired_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            if 'focus' in info:
                st.write(f"**Focus:** {info['focus']}")
            if 'follow_up' in info:
                st.write(f"**Follow-up:** {info['follow_up']}")
            st.write(f"**Alternatives:** {info['alternatives']}")

def show_advanced_tests():
    """Show information about advanced multivariate tests"""

    st.markdown("### Multivariate Analysis of Variance")

    advanced_tests = {
        "MANOVA": {
            "purpose": "Compare means of multiple dependent variables across groups simultaneously",
            "assumptions": ["Multivariate normality", "Homogeneity of covariance matrices", "Independence", "Linear relationships"],
            "when_to_use": "Multiple related dependent variables, want to control for correlations",
            "example": "Comparing effects of diet on weight, cholesterol, and blood pressure simultaneously",
            "effect_size": "Partial eta-squared, Pillai's trace",
            "interpretation": "Tests overall group differences across all dependent variables",
            "advantages": "Controls Type I error, more powerful when variables are correlated",
            "follow_up": "Univariate ANOVAs or discriminant analysis if significant"
        },
        "ANCOVA": {
            "purpose": "Compare group means while controlling for continuous covariates",
            "assumptions": ["Normality", "Homogeneity of variances", "Independence", "Homogeneity of regression slopes"],
            "when_to_use": "Want to control for confounding variables, increase statistical power",
            "example": "Comparing treatment effects on test scores while controlling for baseline IQ",
            "effect_size": "Partial eta-squared",
            "interpretation": "Tests group differences after adjusting for covariate effects",
            "advantages": "Increases power by reducing error variance, controls for confounders",
            "follow_up": "Adjusted pairwise comparisons if main effect is significant"
        }
    }

    for test_name, info in advanced_tests.items():
        with st.expander(f"üî¨ {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Effect Size:** {info['effect_size']}")
                st.write(f"**Advantages:** {info['advantages']}")
            with col2:
                st.write(f"**Key Assumptions:**")
                for assumption in info['assumptions']:
                    st.write(f"‚Ä¢ {assumption}")

            st.write(f"**Example:** {info['example']}")
            st.write(f"**Interpretation:** {info['interpretation']}")
            st.write(f"**Follow-up:** {info['follow_up']}")

def show_posthoc_tests():
    """Show information about post-hoc tests"""

    st.markdown("### Multiple Comparison Procedures")

    st.markdown("""
    <div class="warning-box">
    <p><strong>Important:</strong> Post-hoc tests are used after a significant omnibus test (ANOVA, Kruskal-Wallis)
    to identify which specific groups differ from each other while controlling for multiple comparisons.</p>
    </div>
    """, unsafe_allow_html=True)

    posthoc_tests = {
        "Tukey's HSD": {
            "purpose": "All pairwise comparisons with optimal balance of power and Type I error control",
            "controls": "Family-wise error rate (FWER)",
            "best_for": "Equal sample sizes, homogeneous variances, all pairwise comparisons",
            "when_to_use": "After significant one-way ANOVA with equal group sizes",
            "advantages": "Optimal power among FWER-controlling methods, controls overall Œ±",
            "disadvantages": "Requires equal variances assumption",
            "recommendation": "First choice for most ANOVA follow-ups"
        },
        "Bonferroni correction": {
            "purpose": "Conservative multiple comparison correction",
            "controls": "Family-wise error rate (FWER)",
            "best_for": "Any design, planned comparisons, small number of tests",
            "when_to_use": "When you need very conservative control, planned contrasts",
            "advantages": "Simple to understand and calculate, very conservative",
            "disadvantages": "Low power with many comparisons, overly conservative",
            "recommendation": "Use for planned comparisons or when being conservative is important"
        },
        "Holm-≈†√≠d√°k method": {
            "purpose": "Sequential testing method more powerful than Bonferroni",
            "controls": "Family-wise error rate (FWER)",
            "best_for": "Multiple comparisons where order of testing doesn't matter",
            "when_to_use": "Want more power than Bonferroni while controlling FWER",
            "advantages": "More powerful than Bonferroni, still controls FWER",
            "disadvantages": "More complex than Bonferroni, sequential nature",
            "recommendation": "Good alternative to Bonferroni for exploratory analysis"
        },
        "Benjamini-Hochberg": {
            "purpose": "Controls false discovery rate instead of family-wise error rate",
            "controls": "False Discovery Rate (FDR)",
            "best_for": "Exploratory research, large number of comparisons",
            "when_to_use": "Many comparisons, exploratory analysis, genomics research",
            "advantages": "Much more powerful than FWER methods with many tests",
            "disadvantages": "Allows some false positives, less familiar to many researchers",
            "recommendation": "Excellent for exploratory research with many comparisons"
        },
        "Dunn's test": {
            "purpose": "Non-parametric post-hoc test for Kruskal-Wallis follow-up",
            "controls": "Family-wise error rate (FWER)",
            "best_for": "Follow-up to significant Kruskal-Wallis test",
            "when_to_use": "After significant Kruskal-Wallis test, non-normal data",
            "advantages": "Designed specifically for Kruskal-Wallis follow-up",
            "disadvantages": "Less powerful than parametric alternatives",
            "recommendation": "Standard choice for Kruskal-Wallis post-hoc analysis"
        },
        "Games-Howell": {
            "purpose": "Post-hoc test that handles unequal variances and sample sizes",
            "controls": "Family-wise error rate (FWER)",
            "best_for": "Unequal variances, unequal sample sizes",
            "when_to_use": "When Levene's test shows unequal variances",
            "advantages": "Robust to unequal variances and sample sizes",
            "disadvantages": "More complex calculations, less familiar",
            "recommendation": "Use when assumption of equal variances is violated"
        }
    }

    for test_name, info in posthoc_tests.items():
        with st.expander(f"üìä {test_name}"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**Controls:** {info['controls']}")
                st.write(f"**Best For:** {info['best_for']}")
                st.write(f"**Advantages:** {info['advantages']}")
            with col2:
                st.write(f"**When to Use:** {info['when_to_use']}")
                st.write(f"**Disadvantages:** {info['disadvantages']}")

            st.markdown(f"**üí° Recommendation:** {info['recommendation']}")

    # Decision guide
    st.markdown("### üéØ Post-Hoc Test Selection Guide")

    decision_guide = """
    | Situation | Recommended Test | Rationale |
    |-----------|------------------|-----------|
    | Significant one-way ANOVA, equal variances | Tukey's HSD | Optimal balance of power and error control |
    | Significant one-way ANOVA, unequal variances | Games-Howell | Robust to assumption violations |
    | Significant Kruskal-Wallis test | Dunn's test | Designed for non-parametric follow-up |
    | Planned comparisons (few tests) | Bonferroni | Conservative, simple, appropriate for planned tests |
    | Exploratory analysis (many tests) | Benjamini-Hochberg | More powerful for multiple comparisons |
    | Need maximum power while controlling FWER | Holm-≈†√≠d√°k | More powerful than Bonferroni |
    """

    st.markdown(decision_guide)

def show_power_analysis_info():
    """Show information about power analysis"""

    st.markdown("### Statistical Power Concepts")

    power_concepts = {
        "Statistical Power": {
            "definition": "The probability of correctly rejecting a false null hypothesis (1 - Œ≤)",
            "typical_value": "0.80 (80%) is the conventional standard",
            "interpretation": "80% power means 80% chance of detecting a true effect if it exists",
            "factors": "Depends on effect size, sample size, alpha level, and test type",
            "importance": "Low power leads to high risk of missing real effects (Type II error)"
        },
        "Effect Size": {
            "definition": "Standardized measure of the magnitude of difference or relationship",
            "examples": "Cohen's d, eta-squared, correlation coefficient",
            "conventions": "Small (d=0.2), Medium (d=0.5), Large (d=0.8) for Cohen's d",
            "importance": "Determines practical significance beyond statistical significance",
            "consideration": "Should be based on practical/clinical importance, not just conventions"
        },
        "Sample Size": {
            "definition": "Number of observations needed to achieve desired power",
            "relationship": "Larger samples provide more power to detect smaller effects",
            "calculation": "Based on desired power, effect size, and alpha level",
            "practical": "Must balance statistical requirements with practical constraints",
            "recommendation": "Calculate before data collection, not after"
        }
    }

    for concept, info in power_concepts.items():
        with st.expander(f"üìä {concept}"):
            for key, value in info.items():
                st.write(f"**{key.replace('_', ' ').title()}:** {value}")

    st.markdown("### üéØ Power Analysis Applications")

    applications = {
        "Prospective (Planning)": {
            "purpose": "Determine required sample size before data collection",
            "inputs": "Expected effect size, desired power (usually 80%), alpha level (usually 0.05)",
            "outputs": "Minimum sample size needed",
            "benefits": "Ensures adequate power, prevents underpowered studies",
            "example": "Need 64 subjects per group to detect medium effect (d=0.5) with 80% power"
        },
        "Retrospective (Post-hoc)": {
            "purpose": "Calculate achieved power after data collection",
            "inputs": "Observed effect size, actual sample size, alpha level",
            "outputs": "Statistical power achieved",
            "benefits": "Helps interpret non-significant results",
            "example": "Study with n=20 per group achieved only 35% power to detect medium effect"
        },
        "Sensitivity Analysis": {
            "purpose": "Determine minimum detectable effect size for given sample and power",
            "inputs": "Sample size, desired power, alpha level",
            "outputs": "Minimum effect size detectable",
            "benefits": "Shows what effects the study can realistically detect",
            "example": "With n=30 per group, can detect effects of d=0.73 or larger with 80% power"
        }
    }

    for analysis_type, info in applications.items():
        with st.expander(f"‚ö° {analysis_type} Power Analysis"):
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**Purpose:** {info['purpose']}")
                st.write(f"**Inputs:** {info['inputs']}")
                st.write(f"**Outputs:** {info['outputs']}")
            with col2:
                st.write(f"**Benefits:** {info['benefits']}")
                st.write(f"**Example:** {info['example']}")

    # Effect size guidelines
    st.markdown("### üìè Effect Size Guidelines")

    effect_size_table = """
    | Test Type | Effect Size Measure | Small | Medium | Large |
    |-----------|-------------------|--------|---------|--------|
    | t-test | Cohen's d | 0.2 | 0.5 | 0.8 |
    | ANOVA | Eta-squared (Œ∑¬≤) | 0.01 | 0.06 | 0.14 |
    | Correlation | Pearson's r | 0.1 | 0.3 | 0.5 |
    | Chi-square | Cram√©r's V | 0.1 | 0.3 | 0.5 |
    """

    st.markdown(effect_size_table)

    st.markdown("""
    <div class="info-box">
    <p><strong>Note:</strong> These are general conventions. Effect sizes should be interpreted in the context
    of your specific field and research question. A "small" effect might be very important in some contexts.</p>
    </div>
    """, unsafe_allow_html=True)

def load_sample_dataset(dataset_name):
    """Load a sample dataset for demonstration"""

    np.random.seed(42)

    if dataset_name == "Biological Growth Study":
        n = 50
        control = np.random.normal(10, 2, n)
        treatment = np.random.normal(12, 2.5, n)
        data = pd.DataFrame({
            'growth_rate': np.concatenate([control, treatment]),
            'group': ['Control'] * n + ['Treatment'] * n,
            'replicate': list(range(1, n+1)) * 2
        })
    elif dataset_name == "Gene Expression":
        n = 30
        baseline = np.random.lognormal(2, 0.5, n)
        stimulated = np.random.lognormal(2.3, 0.6, n)
        data = pd.DataFrame({
            'expression_level': np.concatenate([baseline, stimulated]),
            'condition': ['Baseline'] * n + ['Stimulated'] * n,
            'subject_id': list(range(1, n+1)) * 2
        })
    else:
        # Default dataset
        data = pd.DataFrame({
            'value': np.random.normal(0, 1, 100),
            'group': np.random.choice(['A', 'B'], 100)
        })

    return data

def show_advanced_analysis_page():
    """Display advanced statistical analysis options"""

    st.markdown('<h2 class="section-header">üî¨ Advanced Statistical Analysis</h2>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <p>Advanced statistical methods for complex research questions.</p>
    </div>
    """, unsafe_allow_html=True)

    # Check if data is available
    if st.session_state.data is None:
        st.warning("Please upload data in the 'Data Upload & Analysis' section first.")
        return

    data = st.session_state.data
    st.write(f"**Current Dataset:** {data.shape[0]} rows, {data.shape[1]} columns")

    # Advanced test selection
    advanced_test = st.selectbox(
        "Select Advanced Test:",
        ["MANOVA", "ANCOVA", "Logistic Regression", "Multiple Linear Regression", "Two-way ANOVA"]
    )

    advanced_tests = AdvancedStatisticalTests()

    if advanced_test == "MANOVA":
        st.subheader("Multivariate Analysis of Variance (MANOVA)")

        # Variable selection
        numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()

        dependent_vars = st.multiselect("Select dependent variables (continuous):", numeric_columns)
        independent_var = st.selectbox("Select independent variable (categorical):", categorical_columns)

        if len(dependent_vars) >= 2 and independent_var:
            if st.button("Perform MANOVA"):
                with st.spinner("Running MANOVA..."):
                    results = advanced_tests.perform_manova(data, dependent_vars, independent_var)

                    if 'error' not in results:
                        st.success("MANOVA completed!")

                        # Display results
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Wilks' Lambda", f"{results['wilks_lambda']:.4f}")
                            st.metric("F-statistic", f"{results['statistic']:.4f}")
                        with col2:
                            st.metric("P-value", f"{results['p_value']:.6f}")
                            st.metric("Effect Size", f"{results['effect_size']:.4f}")

                        # Group means
                        st.subheader("Group Means")
                        for var in dependent_vars:
                            st.write(f"**{var}:**")
                            means_df = pd.DataFrame(results['group_means'][var], index=['Mean']).T
                            st.dataframe(means_df)
                    else:
                        st.error(results['error'])

    elif advanced_test == "ANCOVA":
        st.subheader("Analysis of Covariance (ANCOVA)")

        numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()

        dependent_var = st.selectbox("Select dependent variable:", numeric_columns)
        independent_var = st.selectbox("Select independent variable (categorical):", categorical_columns)
        covariate = st.selectbox("Select covariate (continuous):", numeric_columns)

        if dependent_var and independent_var and covariate and dependent_var != covariate:
            if st.button("Perform ANCOVA"):
                with st.spinner("Running ANCOVA..."):
                    results = advanced_tests.perform_ancova(data, dependent_var, independent_var, covariate)

                    if 'error' not in results:
                        st.success("ANCOVA completed!")

                        # Display results
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Main Effect F", f"{results['statistic']:.4f}")
                            st.metric("Main Effect p-value", f"{results['p_value']:.6f}")
                        with col2:
                            st.metric("Covariate F", f"{results['covariate_f']:.4f}")
                            st.metric("Covariate p-value", f"{results['covariate_p']:.6f}")

                        st.metric("Effect Size (Œ∑¬≤)", f"{results['effect_size']:.4f}")

                        # Group statistics
                        st.subheader("Adjusted Group Statistics")
                        stats_data = []
                        for group, stats in results['group_statistics'].items():
                            stats_data.append([
                                group, stats['n'],
                                f"{stats['mean_dependent']:.3f}",
                                f"{stats['mean_covariate']:.3f}"
                            ])

                        stats_df = pd.DataFrame(stats_data,
                                              columns=['Group', 'N', f'Mean {dependent_var}', f'Mean {covariate}'])
                        st.dataframe(stats_df)
                    else:
                        st.error(results['error'])

    elif advanced_test == "Logistic Regression":
        st.subheader("Logistic Regression")

        numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
        all_columns = data.columns.tolist()

        # Check for binary variables
        binary_columns = []
        for col in all_columns:
            if data[col].nunique() == 2:
                binary_columns.append(col)

        dependent_var = st.selectbox("Select dependent variable (binary):", binary_columns)
        independent_vars = st.multiselect("Select independent variables:",
                                        [col for col in all_columns if col != dependent_var])

        if dependent_var and independent_vars:
            if st.button("Perform Logistic Regression"):
                with st.spinner("Running Logistic Regression..."):
                    results = advanced_tests.perform_logistic_regression(data, dependent_var, independent_vars)

                    if 'error' not in results:
                        st.success("Logistic Regression completed!")

                        # Display results
                        st.metric("Accuracy", f"{results['accuracy']:.4f}")
                        st.metric("Pseudo R¬≤", f"{results['pseudo_r_squared']:.4f}")

                        # Coefficients and odds ratios
                        st.subheader("Coefficients and Odds Ratios")
                        coef_data = []
                        for var in independent_vars:
                            coef_data.append([
                                var,
                                f"{results['coefficients'][var]:.4f}",
                                f"{results['odds_ratios'][var]:.4f}"
                            ])

                        coef_df = pd.DataFrame(coef_data, columns=['Variable', 'Coefficient', 'Odds Ratio'])
                        st.dataframe(coef_df)

                        # Classification report
                        st.subheader("Classification Performance")
                        class_report = results['classification_report']
                        st.write(f"**Precision (Class 1):** {class_report['1']['precision']:.3f}")
                        st.write(f"**Recall (Class 1):** {class_report['1']['recall']:.3f}")
                        st.write(f"**F1-Score (Class 1):** {class_report['1']['f1-score']:.3f}")
                    else:
                        st.error(results['error'])

def show_power_analysis_page():
    """Display power analysis and sample size calculation page"""

    st.markdown('<h2 class="section-header">‚ö° Power Analysis & Sample Size Calculation</h2>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <p>Calculate statistical power and determine appropriate sample sizes for your research.</p>
    </div>
    """, unsafe_allow_html=True)

    power_analyzer = PowerAnalysis()

    analysis_type = st.selectbox(
        "Select Analysis Type:",
        ["Sample Size Calculation", "Power Calculation", "Comprehensive Analysis"]
    )

    test_type = st.selectbox(
        "Select Test Type:",
        ["t-test", "ANOVA", "Correlation", "Chi-square"]
    )

    if analysis_type == "Sample Size Calculation":
        st.subheader("Calculate Required Sample Size")

        col1, col2 = st.columns(2)
        with col1:
            effect_size = st.slider("Effect Size", 0.1, 2.0, 0.5, 0.1)
            power = st.slider("Desired Power", 0.5, 0.99, 0.8, 0.01)
        with col2:
            alpha = st.slider("Alpha Level", 0.001, 0.1, 0.05, 0.001)

        if test_type == "t-test":
            test_design = st.selectbox("Test Design:", ["two-sample", "one-sample", "paired"])
        elif test_type == "ANOVA":
            num_groups = st.number_input("Number of Groups:", 3, 10, 3)

        if st.button("Calculate Sample Size"):
            with st.spinner("Calculating..."):
                try:
                    if test_type == "t-test":
                        n_required = power_analyzer.calculate_sample_size_ttest(
                            effect_size, power, alpha, test_design
                        )
                    elif test_type == "ANOVA":
                        n_required = power_analyzer.calculate_sample_size_anova(
                            effect_size, num_groups, power, alpha
                        )
                    elif test_type == "Correlation":
                        n_required = power_analyzer.calculate_sample_size_correlation(
                            effect_size, power, alpha
                        )
                    elif test_type == "Chi-square":
                        n_required = power_analyzer.calculate_sample_size_chisquare(
                            effect_size, 1, power, alpha
                        )

                    if n_required:
                        st.success(f"Required sample size: **{n_required}** participants per group")

                        # Additional context
                        st.markdown(f"""
                        **Analysis Parameters:**
                        - Effect size: {effect_size}
                        - Desired power: {power} ({power*100:.0f}%)
                        - Alpha level: {alpha}
                        - Test type: {test_type}
                        """)

                        # Recommendations
                        st.markdown("""
                        **Recommendations:**
                        - Consider adding 10-20% more participants to account for dropouts
                        - Verify that this sample size is feasible for your study
                        - Consider the practical significance of your effect size
                        """)
                    else:
                        st.error("Unable to calculate sample size with these parameters.")

                except Exception as e:
                    st.error(f"Calculation failed: {str(e)}")

    elif analysis_type == "Power Calculation":
        st.subheader("Calculate Statistical Power")

        col1, col2 = st.columns(2)
        with col1:
            effect_size = st.slider("Effect Size", 0.1, 2.0, 0.5, 0.1)
            sample_size = st.number_input("Sample Size per Group:", 5, 1000, 30)
        with col2:
            alpha = st.slider("Alpha Level", 0.001, 0.1, 0.05, 0.001)

        if test_type == "t-test":
            test_design = st.selectbox("Test Design:", ["two-sample", "one-sample", "paired"])
        elif test_type == "ANOVA":
            num_groups = st.number_input("Number of Groups:", 3, 10, 3)

        if st.button("Calculate Power"):
            with st.spinner("Calculating..."):
                try:
                    if test_type == "t-test":
                        power = power_analyzer.calculate_power_ttest(
                            effect_size, sample_size, alpha, test_design
                        )
                    elif test_type == "ANOVA":
                        power = power_analyzer.calculate_power_anova(
                            effect_size, sample_size, num_groups, alpha
                        )
                    elif test_type == "Correlation":
                        power = power_analyzer.calculate_power_correlation(
                            effect_size, sample_size, alpha
                        )
                    elif test_type == "Chi-square":
                        power = power_analyzer.calculate_power_chisquare(
                            effect_size, sample_size, 1, alpha
                        )

                    if power is not None:
                        # Color code power level
                        if power >= 0.8:
                            power_color = "green"
                            power_assessment = "Adequate"
                        elif power >= 0.6:
                            power_color = "orange"
                            power_assessment = "Moderate"
                        else:
                            power_color = "red"
                            power_assessment = "Low"

                        st.markdown(f"""
                        <div style="text-align: center; padding: 20px; border: 2px solid {power_color}; border-radius: 10px;">
                        <h3 style="color: {power_color};">Statistical Power: {power:.3f} ({power*100:.1f}%)</h3>
                        <p style="color: {power_color}; font-size: 18px;">{power_assessment} Power</p>
                        </div>
                        """, unsafe_allow_html=True)

                        # Interpretation
                        st.markdown(f"""
                        **Interpretation:**
                        - There is a {power*100:.1f}% chance of detecting a true effect of size {effect_size}
                        - Risk of Type II error (Œ≤): {(1-power)*100:.1f}%
                        """)

                        if power < 0.8:
                            st.warning("‚ö†Ô∏è Power is below the conventional standard of 80%. Consider increasing sample size.")
                    else:
                        st.error("Unable to calculate power with these parameters.")

                except Exception as e:
                    st.error(f"Calculation failed: {str(e)}")

    else:  # Comprehensive Analysis
        st.subheader("Comprehensive Power Analysis")

        if st.button("Generate Comprehensive Analysis"):
            with st.spinner("Generating comprehensive analysis..."):
                try:
                    # Set default parameters based on test type
                    kwargs = {'power': 0.8, 'alpha': 0.05}
                    if test_type == "ANOVA":
                        kwargs['num_groups'] = 3

                    comprehensive_results = power_analyzer.comprehensive_power_analysis(test_type, **kwargs)

                    st.success("Comprehensive analysis completed!")

                    # Display sample size recommendations
                    st.subheader("Sample Size Recommendations")
                    recommendations = comprehensive_results['sample_size_recommendations']

                    rec_data = []
                    for effect_type, data in recommendations.items():
                        rec_data.append([
                            effect_type.title(),
                            f"{data['effect_size']:.2f}",
                            f"{data['sample_size_required']}" if data['sample_size_required'] else "N/A"
                        ])

                    rec_df = pd.DataFrame(rec_data, columns=['Effect Size', 'Value', 'Sample Size Required'])
                    st.dataframe(rec_df)

                    # Power curves
                    st.subheader("Power Curves")
                    st.write("Power vs. Sample Size for Different Effect Sizes")

                    # Create power curve plot
                    import plotly.graph_objects as go
                    fig = go.Figure()

                    colors = ['blue', 'orange', 'green']
                    for i, (effect_name, curve_data) in enumerate(comprehensive_results['power_curves'].items()):
                        fig.add_trace(go.Scatter(
                            x=curve_data['sample_sizes'],
                            y=curve_data['powers'],
                            mode='lines',
                            name=f'{effect_name.title()} Effect (d={curve_data["effect_size"]})',
                            line=dict(color=colors[i % len(colors)])
                        ))

                    # Add horizontal line at 80% power
                    fig.add_hline(y=0.8, line_dash="dash", line_color="red",
                                 annotation_text="80% Power Threshold")

                    fig.update_layout(
                        title=f"Power Analysis for {test_type.title()}",
                        xaxis_title="Sample Size per Group",
                        yaxis_title="Statistical Power",
                        height=500
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    # Interpretation
                    interpretation = power_analyzer.interpret_power_analysis(comprehensive_results)
                    st.markdown(interpretation)

                except Exception as e:
                    st.error(f"Comprehensive analysis failed: {str(e)}")

if __name__ == "__main__":
    main()